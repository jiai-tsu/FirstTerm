{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_20210406.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gkLamS6XGmO9",
        "nBwlX2dtGpx0",
        "xVN-tZryDSsq",
        "G40guW8yDYPF",
        "EzltX8APDbOf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soI_nDCl7GR8"
      },
      "source": [
        "## 40. 因子分析（Factor Analysis）　続き"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJH4GNsgC-D8"
      },
      "source": [
        "### <font color = blue>**3.** </font> Bayesian PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkLamS6XGmO9"
      },
      "source": [
        "#### <font color = green>**1.** </font> PCAとPPCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "www0hHQwIoWX"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris, load_boston\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA, FactorAnalysis\n",
        "\n",
        "from pandas import DataFrame\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkZnbzTvGHlw"
      },
      "source": [
        "iris = load_iris()\n",
        "df_iris = DataFrame(iris.data)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(df_iris)\n",
        "X_iris = sc.transform(df_iris)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S92RhEhmGRM3"
      },
      "source": [
        "cr_iris = DataFrame(np.corrcoef(X_iris.T))\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.heatmap(cr_iris, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu8we5tGGYAa"
      },
      "source": [
        "pca_iris = PCA()\n",
        "pca_iris.fit(X_iris)\n",
        "pca_iris_W = np.fliplr(pca_iris.components_.T @ np.sqrt(np.diag(pca_iris.explained_variance_)))\n",
        "\n",
        "fa_0_iris = FactorAnalysis(noise_variance_init=np.zeros(iris.data.shape[1]))\n",
        "fa_0_iris.fit(X_iris)\n",
        "fa_0_iris_W = np.fliplr(fa_0_iris.components_.T)\n",
        "\n",
        "ppca_iris = FactorAnalysis()\n",
        "ppca_iris.fit(X_iris)\n",
        "ppca_iris_W = np.fliplr(ppca_iris.components_.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Di5Or7GhBS"
      },
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(pca_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.heatmap(fa_0_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(ppca_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_EjGE4kZuUQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QQKpCG8UNeX"
      },
      "source": [
        "boston = load_boston()\n",
        "df_boston = DataFrame(boston.data)\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(df_boston)\n",
        "X_boston = sc.transform(df_boston)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3q5WgHnUNWM"
      },
      "source": [
        "pca_boston = PCA()\n",
        "pca_boston.fit(X_boston)\n",
        "pca_boston_W = np.fliplr(pca_boston.components_.T @ np.sqrt(np.diag(pca_boston.explained_variance_)))\n",
        "\n",
        "fa_0_boston = FactorAnalysis(noise_variance_init=np.zeros(boston.data.shape[1]))\n",
        "fa_0_boston.fit(X_boston)\n",
        "fa_0_boston_W = np.fliplr(fa_0_boston.components_.T)\n",
        "\n",
        "ppca_boston = FactorAnalysis()\n",
        "ppca_boston.fit(X_boston)\n",
        "ppca_boston_W = np.fliplr(ppca_boston.components_.T)\n",
        "\n",
        "plt.figure(figsize=(25,8))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(pca_boston_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.heatmap(fa_0_boston_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(ppca_boston_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzUJ1aILUM7I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXmq4Kl97-p0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBwlX2dtGpx0"
      },
      "source": [
        "#### <font color = green>**2.** </font> ヒントン図"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-t46YYyGyyI"
      },
      "source": [
        "## 出典：https://qiita.com/ctgk/items/89c11192affe7f236852"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9fcLtYH_eWp"
      },
      "source": [
        "def hinton(matrix, max_weight=None, ax=None):\n",
        "  \"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"\n",
        "  ax = ax if ax is not None else plt.gca()\n",
        "\n",
        "  if not max_weight:\n",
        "    max_weight = 2 ** np.ceil(np.log(np.abs(matrix).max()) / np.log(2))\n",
        "\n",
        "  ax.patch.set_facecolor('gray')\n",
        "  ax.set_aspect('equal', 'box')\n",
        "  ax.xaxis.set_major_locator(plt.NullLocator())\n",
        "  ax.yaxis.set_major_locator(plt.NullLocator())\n",
        "\n",
        "  for (x, y), w in np.ndenumerate(matrix):\n",
        "    color = 'white' if w > 0 else 'black'\n",
        "    size = np.sqrt(np.abs(w) / max_weight)\n",
        "    rect = plt.Rectangle([y - size / 2, x - size / 2], size, size,\n",
        "                         facecolor=color, edgecolor=color)\n",
        "    ax.add_patch(rect)\n",
        "\n",
        "  ax.autoscale_view()\n",
        "  ax.invert_yaxis()\n",
        "  plt.xlim(-0.5, np.size(matrix, 1) - 0.5)\n",
        "  plt.ylim(-0.5, len(matrix) - 0.5)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IDmxqoApI7e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghTy1R_p8d2j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvJNodUl8eI1"
      },
      "source": [
        "plt.figure(figsize=(18,6))\n",
        "plt.subplot(1, 3, 1)\n",
        "sns.heatmap(pca_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 2)\n",
        "sns.heatmap(fa_0_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 3, 3)\n",
        "sns.heatmap(ppca_iris_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVWBQWl2D-b2"
      },
      "source": [
        "hinton(np.flipud(pca_iris_W))\n",
        "\n",
        "hinton(np.flipud(ppca_iris_W))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4-5OGwyGkCs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it91RbCyGj-r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jwCgX0J83Qr"
      },
      "source": [
        "plt.figure(figsize=(17,8))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(pca_boston_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(ppca_boston_W, annot=True, square=True, \n",
        "            vmin=-1,vmax=1, fmt='.2f', cmap='RdBu')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6kWDVaxD9hT"
      },
      "source": [
        "hinton(np.flipud(pca_boston_W))\n",
        "\n",
        "hinton(np.flipud(ppca_boston_W))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e19UzVBvGq5H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jCt5yVO73Gg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR76sNkOB7ci"
      },
      "source": [
        "## 42. 変分ベイズ（Variational Bayes）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVN-tZryDSsq"
      },
      "source": [
        "### <font color = blue>**1.** </font> Simple Variational Inference for 2D Gaussian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boIcmNo9EGXs"
      },
      "source": [
        "## 出典(Julia)：https://github.com/sammy-suyama/MLBlog/blob/master/src/demo_simpleVI.jl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyOttVF-A8z9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30DAGBTpG3Pn"
      },
      "source": [
        "def calc_KL(mu1, lambda1, mu2, lambda2):\n",
        "  D = len(mu1)\n",
        "  px_lnqx = 0.5 * np.log(np.linalg.det(lambda2)) \\\n",
        "              - 0.5 * ((mu1 - mu2).T @ lambda2 @ (mu1 - mu2) \\\n",
        "              + np.trace(lambda2 @ np.linalg.inv(lambda1)))\n",
        "  px_lnpx = 0.5 * np.log(np.linalg.det(lambda1)) \\\n",
        "              - 0.5 * D\n",
        "  KL = - (px_lnqx - px_lnpx)\n",
        "  return KL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5abEyh4RH5Qj"
      },
      "source": [
        "## creat truth distribution\n",
        "\n",
        "D = 2 # dimension\n",
        "theta = 2*np.pi/12  # tilt\n",
        "\n",
        "A = np.array([[np.cos(theta), -np.sin(theta)],\n",
        "              [np.sin(theta), np.cos(theta)]])\n",
        "\n",
        "mu_true = [.0, .0]\n",
        "\n",
        "lambda_true = np.linalg.inv(A @ np.linalg.inv(np.diag([1,10])) @ A.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEldf34VH6Aq"
      },
      "source": [
        "## initialize\n",
        "\n",
        "mu_h = np.random.randn(D)\n",
        "lambda_h = np.zeros([D,D])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQhMLMhqT9RO"
      },
      "source": [
        "mu_h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNzTKARTG90F"
      },
      "source": [
        "## main iteration\n",
        "\n",
        "max_iter = 10\n",
        "KL = []\n",
        "result = []\n",
        "\n",
        "for i in range(max_iter):\n",
        "  ## update\n",
        "  mu_h[0] = mu_true[0] - 1/lambda_true[0,0] * lambda_true[0,1] * (mu_h[1] - mu_true[1])\n",
        "  lambda_h[0,0] = lambda_true[0,0]\n",
        "  mu_h[1] = mu_true[1] - 1/lambda_true[1,1] * lambda_true[1,0] * (mu_h[0] - mu_true[0])\n",
        "  lambda_h[1,1] = lambda_true[1,1]\n",
        "        \n",
        "  ## calculate KL divergeince\n",
        "  KL.append(calc_KL(mu_h, lambda_h, mu_true, lambda_true))\n",
        "\n",
        "  ## store the results\n",
        "  result.append([mu_h.copy(), np.linalg.inv(lambda_h).copy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXR-1tBaG3Kd"
      },
      "source": [
        "def plot_results(result, truth):\n",
        "  N = len(result)\n",
        "  H = int(np.sqrt(N))\n",
        "  W = int(N / H)+1\n",
        "  f, ax = plt.subplots(H, W, figsize=(14,10))\n",
        "  for i in range(H):\n",
        "    for j in range(W):\n",
        "      n = i * W + j\n",
        "      if n < N:\n",
        "        p = ax[i, j]\n",
        "        p.set_title(\"{} of {}\".format(n+1, N))\n",
        "        plot_gaussian(p, result[n][0], result[n][1], \"b\", \"p(z)\")\n",
        "        plot_gaussian(p, truth[0], truth[1], \"r\", \"q(z)\")\n",
        "        p.set_xlim([-2, 2.5]) ###\n",
        "        p.set_ylim([-1, 1.5]) ###\n",
        "  f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPlA4p_FA8yA"
      },
      "source": [
        "def plot_gaussian(p, Mu, Sigma, col, label):\n",
        "  res = 100\n",
        "  p.plot(Mu[0], Mu[1], \"x\", color=col)\n",
        "  val, vec = np.linalg.eig(Sigma)\n",
        "  dw = 2*np.pi/res\n",
        "  w = np.array([dw * i for i in range(res)])\n",
        "    \n",
        "  c = 1.0\n",
        "  a = np.sqrt(abs(c * val[0]))\n",
        "  b = np.sqrt(abs(c * val[1]))\n",
        "  P1 = a*np.cos(w)\n",
        "  P2 = b*np.sin(w)\n",
        "  P3 = vec.T @ np.array([P1, P2])\n",
        "  P = P3.T + Mu\n",
        "  p.plot(P[:, 0].T, P[:, 1].T, \"-\", color=col, label=label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRhCjSiMRFjO"
      },
      "source": [
        "## visualize results\n",
        "\n",
        "lambda_true_inv = np.linalg.inv(lambda_true)\n",
        "plot_results(result, (mu_true, lambda_true_inv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hjXDPDkRFbZ"
      },
      "source": [
        "plt.figure(figsize=(4,3))\n",
        "f, ax = plt.subplots(1, 1)\n",
        "plot_gaussian(ax, mu_true, lambda_true_inv, \"b\", \"p(z)\")\n",
        "plot_gaussian(ax, result[-1][0], result[-1][1], \"r\", \"q(z)\")\n",
        "ax.set_xlabel(\"z_1\", fontsize=16)\n",
        "ax.set_ylabel(\"z_2\", fontsize=16)\n",
        "ax.legend(fontsize=16)\n",
        "f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmfU4HB9G9xR"
      },
      "source": [
        "## KL divergence\n",
        "\n",
        "plt.figure(figsize=(4,3))\n",
        "f, ax = plt.subplots(1)\n",
        "ax.plot(range(max_iter), KL)\n",
        "ax.set_ylabel(\"KL divergence\")\n",
        "ax.set_xlabel(\"iteration\")\n",
        "f.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EikJ3aCCEGSd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Mr6gC2DSdm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G40guW8yDYPF"
      },
      "source": [
        "### <font color = blue>**2.** </font> 変分ベイズによるクラスタリング"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8qQjNXCLQDP"
      },
      "source": [
        "## 出典：https://tips-memo.com/python-vb-gmm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFj2zBThVyRA"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from numpy import linalg as la\n",
        "from scipy.special import digamma, gamma, logsumexp\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cu90CFZkLT5"
      },
      "source": [
        "var = 1\n",
        "data_size = 1000\n",
        "np.random.seed(0)\n",
        "\n",
        "data_1 = np.random.normal(-5, var, data_size)\n",
        "data_2 = np.random.normal(0, var, data_size)\n",
        "data_3 = np.random.normal(5, var, data_size)\n",
        "\n",
        "group1 = np.append(\n",
        "    np.append([data_1], [data_2], 0), \n",
        "    [data_3], 0)\n",
        "\n",
        "group2 = np.append(\n",
        "    np.append([data_3], [data_1], 0), \n",
        "    [data_2], 0)\n",
        "\n",
        "group3 = np.append(\n",
        "    np.append([data_2], [data_3], 0), \n",
        "    [data_1], 0)\n",
        "\n",
        "group4 = np.append(\n",
        "    np.append([data_2], [data_1], 0), \n",
        "    [data_3], 0)\n",
        "\n",
        "l = np.append(\n",
        "      np.append(\n",
        "        np.append(group1, group2, 1), \n",
        "        group3, 1), \n",
        "      group4, 1)\n",
        "l = l.T\n",
        "np.shape(l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NElawrlWp-Je"
      },
      "source": [
        "labels = [1 for i in range(data_size)] \\\n",
        "          + [2 for i in range(data_size)] \\\n",
        "            + [3 for i in range(data_size)] \\\n",
        "              + [4 for i in range(data_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sj2UmrKMXoF"
      },
      "source": [
        "cm = plt.get_cmap(\"tab10\")\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "N = l.shape[0]\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(labels[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BIUe-ekpytt"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=\"grey\", ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICtdSLnZpyry"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA0DJp_yXBG0"
      },
      "source": [
        "class VBGMM():\n",
        "  def __init__(self, K=6, alpha0=0.1):\n",
        "    self.K = K\n",
        "    self.alpha0 = alpha0\n",
        "  \n",
        "  def init_params(self, X):\n",
        "    self.N, self.D = X.shape\n",
        "    self.m0 = np.random.randn(self.D)\n",
        "    self.beta0 = np.array([1.0])\n",
        "    self.W0 = np.eye(self.D)\n",
        "    self.nu0 = np.array([self.D])\n",
        "    \n",
        "    self.N_k = (self.N / self.K) + np.zeros(self.K)\n",
        "    \n",
        "    self.alpha = np.ones(self.K) * self.alpha0\n",
        "    self.beta = np.ones(self.K) * self.beta0\n",
        "    self.m = np.random.randn(self.K, self.D)\n",
        "    self.W = np.tile(self.W0, (self.K, 1, 1))\n",
        "    self.nu = np.ones(self.K)*self.D\n",
        "    \n",
        "    self.Sigma = np.zeros((self.K, self.D, self.D))\n",
        "    for k in range(self.K):\n",
        "      self.Sigma[k] = la.inv(self.nu[k] * self.W[k])\n",
        "    self.Mu = self.m\n",
        "  \n",
        "  def e_step(self, X):\n",
        "    pi = digamma(self.alpha) - digamma(self.alpha.sum())\n",
        "    Lambda_tilde = np.zeros((self.K))\n",
        "    for k in range(self.K):\n",
        "      digamma_sum = np.array([])\n",
        "      for i in range(self.D):\n",
        "        digamma_sum = np.append(digamma_sum, digamma((self.nu[k] + 1 - i)/2))\n",
        "      A = np.sum(digamma_sum)\n",
        "      B = self.D * np.log(2)\n",
        "      C = np.log(la.det(self.W[k]))\n",
        "      Lambda_tilde[k] = A + B + C\n",
        "    rho = np.zeros((self.N, self.K))\n",
        "    for n in range(self.N):\n",
        "      for k in range(self.K):         \n",
        "        gap = (X[n] - self.m[k])[:, None]\n",
        "        A = -(self.D/(2*self.beta[k]))\n",
        "        B = -(self.nu[k]/2)*(gap.T@self.W[k]@gap)\n",
        "        rho[n][k] = pi[k] + 0.5*Lambda_tilde[k] + A + B\n",
        "    r_log = rho - logsumexp(rho, axis=1)[:,None]\n",
        "    r = np.exp(r_log)\n",
        "    r[np.isnan(r)] = 1.0 / (self.K)\n",
        "    return r\n",
        "  \n",
        "  def m_step(self, X, r):\n",
        "      self.N_k = np.sum(r, axis=0, keepdims=True).T\n",
        "      barx = (r.T @ X) / self.N_k\n",
        "      S_list = np.zeros((self.N, self.K, self.D, self.D))\n",
        "      for n in range(self.N):\n",
        "        for k in range(self.K):\n",
        "          gap = (X[n] - barx[k])[:, None]\n",
        "          S_list[n][k] = r[n][k] * gap @ gap.T\n",
        "      S = np.sum(S_list, axis=0) / self.N_k[:,None]\n",
        "      self.alpha = self.alpha0 + self.N_k\n",
        "      self.beta = self.beta0 + self.N_k\n",
        "      for k in range(self.K):  \n",
        "        self.m[k] = (1/self.beta[k]) * (self.beta0 * self.m0 + self.N_k[k] * barx[k])\n",
        "      for k in range(self.K):\n",
        "        gap = (barx[k] - self.m0)[:, None]\n",
        "        A = la.inv(self.W0)\n",
        "        B = self.N_k[k] * S[k]\n",
        "        C = ((self.beta0*self.N_k[k]) / (self.beta0 + self.N_k[k])) * gap@gap.T\n",
        "        self.W[k] = la.inv(A + B + C)\n",
        "        self.nu[k] = self.nu0 + self.N_k[k]\n",
        "      pi = self.alpha / np.sum(self.alpha, keepdims=True)\n",
        "      return pi\n",
        "  \n",
        "  def calc(self, x, mu, sigma_inv, sigma_det):\n",
        "    exp = -0.5*(x - mu).T@sigma_inv.T@(x - mu)\n",
        "    denomin = np.sqrt(sigma_det)*(np.sqrt(2*np.pi)**self.D)\n",
        "    return np.exp(exp)/denomin\n",
        "  \n",
        "  def gauss(self, X, mu, sigma):\n",
        "    output = np.array([])\n",
        "    sigma_inv = la.inv(sigma)\n",
        "    sigma_det = la.det(sigma) + np.spacing(1) ####\n",
        "    for i in range(self.N):\n",
        "      output = np.append(output, self.calc(X[i], mu, sigma_inv, sigma_det))\n",
        "    return output\n",
        "  \n",
        "  def mix_gauss(self, X, Mu, Sigma, Pi):\n",
        "    output = np.array([Pi[i]*self.gauss(X, Mu[i], Sigma[i]) for i in range(self.K)])\n",
        "    return output, np.sum(output, 0)[None,:]\n",
        "  \n",
        "  def log_likelihood(self, X, pi):\n",
        "    for i in range(self.K):\n",
        "      self.Sigma[i] = la.inv(self.nu[i] * self.W[i])\n",
        "    self.Mu = self.m\n",
        "    _, out_sum = self.mix_gauss(X, self.Mu, self.Sigma, pi)\n",
        "    logs = np.array([np.log(out_sum[0][n]) for n in range(self.N)])\n",
        "    return np.sum(logs)\n",
        "  \n",
        "  def fit(self, X, iter_max, thr):\n",
        "    self.init_params(X)\n",
        "    log_list = np.array([])\n",
        "    pi = np.array([1/self.K for i in range(self.K)])\n",
        "    log_list = np.append(log_list, self.log_likelihood(X, pi))\n",
        "    count = 0\n",
        "    for i in range(iter_max):\n",
        "      r = self.e_step(X)\n",
        "      pi = self.m_step(X, r)\n",
        "      log_list = np.append(log_list, self.log_likelihood(X, pi))\n",
        "      if np.abs(log_list[count] - log_list[count+1]) < thr:\n",
        "        print(\"fit success Previous log-likelihood gap: {}\"\\\n",
        "                .format(np.abs(log_list[count] - log_list[count+1])))  ####\n",
        "        return count+1, log_list, r, pi, self.Mu, self.Sigma\n",
        "      else:\n",
        "        print(\"{}th Previous log-likelihood gap: {}\"\\\n",
        "                .format(i, np.abs(log_list[count] - log_list[count+1])))  ####\n",
        "        count += 1\n",
        "        \n",
        "  def classify(self, X):\n",
        "    return np.argmax(self.e_step(X), 1)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pFW0EQXmeVa"
      },
      "source": [
        "model = VBGMM(K=8, alpha0=0.01)\n",
        "n_iter, log_list, r, pi, Mu, Sigma = model.fit(l, iter_max=100, thr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJQ1VDevXBFG"
      },
      "source": [
        "labels_predict = model.classify(l)\n",
        "#print(n_iter)\n",
        "#print(log_list)\n",
        "len(set(labels_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IMrELJXXBDK"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(labels_predict[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J21bUqXNVlI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrjkZ4ziNVa9"
      },
      "source": [
        "####################\n",
        "# scikit-learnのライブラリを  #\n",
        "# 使用した場合との比較図示 #\n",
        "####################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYhkdEhsqNWy"
      },
      "source": [
        "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhfxc-aBqNSH"
      },
      "source": [
        "GMM_4 = GaussianMixture(n_components=4)\n",
        "GMM_8 = GaussianMixture(n_components=8)\n",
        "BGMM_4 = BayesianGaussianMixture(n_components=4)\n",
        "BGMM_8 = BayesianGaussianMixture(n_components=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLVQSZzkrO60"
      },
      "source": [
        "gmm_4_label = GMM_4.fit_predict(l)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(gmm_4_label[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRM_-oO1r6BL"
      },
      "source": [
        "gmm_8_label = GMM_8.fit_predict(l)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(gmm_8_label[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytO0rJbmr59D"
      },
      "source": [
        "bgmm_4_label = BGMM_4.fit_predict(l)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(bgmm_4_label[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlZVvKLgr56h"
      },
      "source": [
        "bgmm_8_label = BGMM_8.fit_predict(l)\n",
        "print(\"number of cluster: \", len(set(bgmm_8_label)))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "for n in range(N):\n",
        "  ax.plot([l[n][0]], [l[n][1]], [l[n][2]], \"o\", color=cm(bgmm_8_label[n]), ms=1.5)\n",
        "ax.view_init(elev=30, azim=45)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR70B6B773A8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t_KGIgM72-a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzltX8APDbOf"
      },
      "source": [
        "### <font color = blue>**3.** </font> トピックモデル：LDA（Latent Dirichlet Allocation : 潜在的ディリクレ配分法）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nLUlL-Hm8IQ"
      },
      "source": [
        "$\\downarrow \\downarrow$ 公式リファレンス $\\downarrow \\downarrow$\\\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ_QukzDnUsB"
      },
      "source": [
        "## 出典: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
        "\n",
        "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
        "#         Lars Buitinck\n",
        "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
        "# License: BSD 3 clause"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vaZtvfMnVWR"
      },
      "source": [
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqAHBWaEnVUL"
      },
      "source": [
        "n_samples = 2000\n",
        "n_features = 1000\n",
        "n_components = 10\n",
        "n_top_words = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R96kheZXnZ2w"
      },
      "source": [
        "def plot_top_words(model, feature_names, n_top_words, title):\n",
        "  fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
        "  axes = axes.flatten()\n",
        "  for topic_idx, topic in enumerate(model.components_):\n",
        "    top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
        "    top_features = [feature_names[i] for i in top_features_ind]\n",
        "    weights = topic[top_features_ind]\n",
        "\n",
        "    ax = axes[topic_idx]\n",
        "    ax.barh(top_features, weights, height=0.7)\n",
        "    ax.set_title(f'Topic {topic_idx +1}',\n",
        "                 fontdict={'fontsize': 30})\n",
        "    ax.invert_yaxis()\n",
        "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
        "    for i in 'top right left'.split():\n",
        "      ax.spines[i].set_visible(False)\n",
        "    fig.suptitle(title, fontsize=40)\n",
        "\n",
        "  plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34OtsBwmnZ0q"
      },
      "source": [
        "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
        "# to filter out useless terms early on: the posts are stripped of headers,\n",
        "# footers and quoted replies, and common English words, words occurring in\n",
        "# only one document or in at least 95% of the documents are removed.\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "t0 = time()\n",
        "data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n",
        "                             remove=('headers', 'footers', 'quotes'),\n",
        "                             return_X_y=True)\n",
        "data_samples = data[:n_samples]\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEVhJ-0HnVSS"
      },
      "source": [
        "# Use tf-idf features for NMF.\n",
        "\n",
        "print(\"Extracting tf-idf features for NMF...\")\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
        "                                   max_features=n_features,\n",
        "                                   stop_words='english')\n",
        "t0 = time()\n",
        "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4_31xiUnqpd"
      },
      "source": [
        "# Use tf (raw term count) features for LDA.\n",
        "\n",
        "print(\"Extracting tf features for LDA...\")\n",
        "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
        "                                max_features=n_features,\n",
        "                                stop_words='english')\n",
        "t0 = time()\n",
        "tf = tf_vectorizer.fit_transform(data_samples)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T62nJ2dnqkD"
      },
      "source": [
        "# Fit the NMF model\n",
        "\n",
        "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfGyER42nwlo"
      },
      "source": [
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "plot_top_words(nmf, tfidf_feature_names, n_top_words,\n",
        "               'Topics in NMF model (Frobenius norm)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b87wuI-InwjB"
      },
      "source": [
        "# Fit the NMF model\n",
        "\n",
        "print('\\n' * 2, \"Fitting the NMF model (generalized Kullback-Leibler \"\n",
        "      \"divergence) with tf-idf features, n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))\n",
        "\n",
        "t0 = time()\n",
        "nmf = NMF(n_components=n_components, random_state=1,\n",
        "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
        "          l1_ratio=.5).fit(tfidf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pr0Yf9an0oE"
      },
      "source": [
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "plot_top_words(nmf, tfidf_feature_names, n_top_words,\n",
        "               'Topics in NMF model (generalized Kullback-Leibler divergence)')\n",
        "\n",
        "print('\\n' * 2, \"Fitting LDA models with tf features, \"\n",
        "      \"n_samples=%d and n_features=%d...\"\n",
        "      % (n_samples, n_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbhpGLrnn0lg"
      },
      "source": [
        "lda = LatentDirichletAllocation(n_components=n_components,\n",
        "                                max_iter=5,\n",
        "                                learning_method='online',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0oos2R1oDD7"
      },
      "source": [
        "t0 = time()\n",
        "lda.fit(tf)\n",
        "print(\"done in %0.3fs.\" % (time() - t0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg4FfneIm7uB"
      },
      "source": [
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "plot_top_words(lda, tf_feature_names, n_top_words, 'Topics in LDA model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEvRtAu5mwC3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5K6dB9_727N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}