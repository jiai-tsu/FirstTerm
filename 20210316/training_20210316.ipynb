{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_20210316.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "EKA9P5hi9I9S",
        "TyOSFQf192Eo",
        "Cqz1ZesT6wJK",
        "v77rlkCKW0IJ",
        "OkH-kazQecHB",
        "rlx56nQtfe8Y",
        "CqwV-CRdS6Nv",
        "Tb0CsZ2bwvYm",
        "JMPi6xdrFhwE",
        "IQ_EWBhaxjcm",
        "t6TC1go86i68",
        "UYTk3Ahf9u67",
        "wHoFqTqEIwLZ",
        "SjPQR56RIwLg",
        "S9IeUQK8IwLj",
        "tgsbCXf6IwLk",
        "-0SM0ZS_AEBf",
        "VkGzLvSA6Jwm",
        "4Jl7Gj3Its6z",
        "s2d9S2CSSO1z",
        "Qv6abtRvH4xO",
        "9fbTyfJpNr7x",
        "kkAXLtuyWWDI",
        "FSwymsbkbLDA",
        "fVo_AnT0l26j"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKA9P5hi9I9S"
      },
      "source": [
        "## 37.  データ拡張（Data Augmentation）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTPQ2D9c9VXh"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvF-kNsD9Xk2"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"stanford_dogs\", split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        "    )\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEiQfEst8JaP"
      },
      "source": [
        "IMG_SIZE = 224\n",
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0H37Ti_8KuI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def format_label(label):\n",
        "  string_label = label_info.int2str(label)\n",
        "  return string_label.split(\"-\")[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TohFJOK98KlX"
      },
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "label_info = ds_info.features[\"label\"]\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "  plt.title(\"{}\".format(format_label(label)))\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJuAN-2e8Kc9"
      },
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ1DhHtD8Fje"
      },
      "source": [
        "img_augmentation = Sequential(\n",
        "    [preprocessing.RandomRotation(factor=0.15), ###\n",
        "     preprocessing.RandomTranslation(height_factor=0.1, ### \n",
        "                                     width_factor=0.1), ###\n",
        "     preprocessing.RandomFlip(),\n",
        "     preprocessing.RandomZoom(height_factor=(-0.8, 0.6)), ###\n",
        "     preprocessing.RandomContrast(factor=0.1),  ###\n",
        "     ],\n",
        "     name=\"img_augmentation\",)\n",
        "\n",
        "image_index = 0 ###\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "for image, label in ds_train.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
        "    plt.imshow(aug_img[image_index].numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Son-hBY7-E_6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQvL2FQM-Fss"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltuS65bP99jK"
      },
      "source": [
        "img_augmentation = Sequential(\n",
        "    [preprocessing.RandomRotation(factor=0.15), ###\n",
        "     preprocessing.RandomTranslation(height_factor=0.1, ### \n",
        "                                     width_factor=0.1), ###\n",
        "     preprocessing.RandomFlip(),\n",
        "     preprocessing.RandomZoom(height_factor=(-0.8, 0.6)), ###\n",
        "     preprocessing.RandomContrast(factor=0.1),  ###\n",
        "     ],\n",
        "     name=\"img_augmentation\",)\n",
        "\n",
        "image_index = 0 ###\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "for image, label in ds_train.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
        "    plt.imshow(aug_img[image_index].numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDabQStU99dr"
      },
      "source": [
        "img_augmentation = Sequential(\n",
        "    [preprocessing.RandomRotation(factor=0.15), ###\n",
        "     preprocessing.RandomTranslation(height_factor=0.1, ### \n",
        "                                     width_factor=0.1), ###\n",
        "     preprocessing.RandomFlip(),\n",
        "     preprocessing.RandomZoom(height_factor=(-0.8, 0.6)), ###\n",
        "     preprocessing.RandomContrast(factor=0.1),  ###\n",
        "     ],\n",
        "     name=\"img_augmentation\",)\n",
        "\n",
        "image_index = 0 ###\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "for image, label in ds_train.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
        "    plt.imshow(aug_img[image_index].numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AApGcclw99Xu"
      },
      "source": [
        "img_augmentation = Sequential(\n",
        "    [preprocessing.RandomRotation(factor=0.15), ###\n",
        "     preprocessing.RandomTranslation(height_factor=0.1, ### \n",
        "                                     width_factor=0.1), ###\n",
        "     preprocessing.RandomFlip(),\n",
        "     preprocessing.RandomZoom(height_factor=(-0.8, 0.6)), ###\n",
        "     preprocessing.RandomContrast(factor=0.1),  ###\n",
        "     ],\n",
        "     name=\"img_augmentation\",)\n",
        "\n",
        "image_index = 0 ###\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "for image, label in ds_train.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    aug_img = img_augmentation(tf.expand_dims(image, axis=0))\n",
        "    plt.imshow(aug_img[image_index].numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwcBfzUl-GTv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnc6EC7C9Quv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyOSFQf192Eo"
      },
      "source": [
        "## 38. 転移学習（transfer learning）と fine-tuning\n",
        "\n",
        "<font color=red size=5>**ノートブックの設定からGPUを選択すること**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HANo7NDGoODG"
      },
      "source": [
        "[転移学習のサーベイ](https://www.kamishima.net/archive/2009-tr-jsai_dmsm1-PR.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-yImOtgoZIw"
      },
      "source": [
        "[転移学習を用いたデータ解析](https://datachemeng.com/transfer_learning/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqz1ZesT6wJK"
      },
      "source": [
        "### <font color = blue>**1.** </font> 公式チュートリアル\n",
        "\n",
        "https://www.tensorflow.org/tutorials/images/transfer_learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2X4KyhORdSeO"
      },
      "source": [
        "- 事前学習済みネットワークを転移学習し、犬と猫の画像の分類を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqOt6Sv7AsMi"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v77rlkCKW0IJ"
      },
      "source": [
        "#### <font color = green> **1.1.** </font> Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4oYaEmxe4r"
      },
      "source": [
        "#### Data download\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (160, 160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(train_dir,\n",
        "                                             shuffle=True,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAvtLwi7_J__"
      },
      "source": [
        "validation_dataset = image_dataset_from_directory(validation_dir,\n",
        "                                                  shuffle=True,\n",
        "                                                  batch_size=BATCH_SIZE,\n",
        "                                                  image_size=IMG_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BeQyKThC_Y"
      },
      "source": [
        "### Show the first nine images and labels from the training set:\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFFIYrTFV9RO"
      },
      "source": [
        "###\n",
        "# As the original dataset doesn't contains a test set, you will create one.\n",
        "# To do so, determine how many batches of data are available in the\n",
        "# validation set using ```tf.data.experimental.cardinality```, then move\n",
        "# 20% of them to a test set.\n",
        "\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9pFlFWgBKgH"
      },
      "source": [
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3UUPdm86LNC"
      },
      "source": [
        "#### Configure the dataset for performance\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P99QiMGit1A"
      },
      "source": [
        "#### Use data augmentation\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9SlcbhrarOO"
      },
      "source": [
        "Note : \n",
        "- These layers are active only during training, when you call `model.fit`.\n",
        "- They are inactive when the model is used in inference mode in `model.evaulate` or `model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQullOUHkm67"
      },
      "source": [
        "### Let's repeatedly apply these layers to the same image and see the result.\n",
        "\n",
        "for image, _ in train_dataset.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = image[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
        "    plt.imshow(augmented_image[0] / 255)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO0HM9JAQUFq"
      },
      "source": [
        "#### Rescale pixel values\n",
        "# In a moment, you will download `tf.keras.applications.MobileNetV2` for use as your base model.\n",
        "# This model expects pixel vaues in `[-1,1]`, but at this point, the pixel values in your images are in `[0-255]`.\n",
        "# To rescale them, use the preprocessing method included with the model.\n",
        "\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnr81qRMzcs5"
      },
      "source": [
        "Note : Alternatively, you could rescale pixel values from `[0,255]` to `[-1, 1]` using a [Rescaling](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/Rescaling) layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2NyJn4KQMux"
      },
      "source": [
        "rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz7qgImhTxw4"
      },
      "source": [
        "Note : If using other `tf.keras.applications`, be sure to check the API doc to determine if they expect pixels in `[-1,1]` or `[0,1]`, or use the included `preprocess_input` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkTJr0JNtmLx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkH-kazQecHB"
      },
      "source": [
        "#### <font color = green> **1.2.** </font> Create the base model from the pre-trained convnets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19IQ2gqneqmS"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "# This is pre-trained on the ImageNet dataset, a large dataset consisting of 1.4M images and 1000 classes.\n",
        "\n",
        "IMG_SHAPE = IMG_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False, # you load a network that doesn't include the classification layers at the top,\n",
        "                                                                  # which is ideal for feature extraction\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-2LJL0EEUcx"
      },
      "source": [
        "###\n",
        "# This feature extractor converts each `160x160x3` image\n",
        "# into a `5x5x1280` block of features. Let's see what it\n",
        "# does to an example batch of images:\n",
        "\n",
        "image_batch, label_batch = next(iter(train_dataset))\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlx56nQtfe8Y"
      },
      "source": [
        "#### <font color = green> **1.3.** </font> Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTCJH4bphOeo"
      },
      "source": [
        "#### Freeze the convolutional base\n",
        "\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsNHwpm7BeVM"
      },
      "source": [
        "<font color=red> Important note about BatchNormalization layers </font>\n",
        "\n",
        "Many models contain `tf.keras.layers.BatchNormalization` layers. \\\n",
        "This layer is a special case and precautions should be taken in the context of fine-tuning, as shown later in this tutorial. \n",
        "\n",
        "When you set `layer.trainable = False`, the `BatchNormalization` layer will run in inference mode, and will not update its mean and variance statistics. \n",
        "\n",
        "When you unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, you should keep the BatchNormalization layers in inference mode by passing `training = False` when calling the base model. \\\n",
        "Otherwise, the updates applied to the non-trainable weights will destroy what the model has learned.\n",
        "\n",
        "For details, see the [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpbzSmPkDa-N"
      },
      "source": [
        "# Let's take a look at the base model architecture\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLnpMF5KOALm"
      },
      "source": [
        "#### Add a classification head\n",
        "# To generate predictions from the block of features,\n",
        "# average over the spatial `5x5` spatial locations,\n",
        "# using a `tf.keras.layers.GlobalAveragePooling2D` layer\n",
        "# to convert the features to  a single 1280-element vector per image.\n",
        "\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv4afXKj6cVa"
      },
      "source": [
        "###\n",
        "# Apply a `tf.keras.layers.Dense` layer to convert these features into a\n",
        "# single prediction per image. You don't need an activation function here\n",
        "# because this prediction will be treated as a `logit`, or a raw prediction value. \n",
        "# Positive numbers predict class 1, negative numbers predict class 0.\n",
        "\n",
        "prediction_layer = tf.keras.layers.Dense(1)\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgzQX6Veb2WT"
      },
      "source": [
        "###\n",
        "# Build a model by chaining together the data augmentation, rescaling,\n",
        "# base_model and feature extractor layers using the Keras Functional API\n",
        "# (https://www.tensorflow.org/guide/keras/functional).\n",
        "# As previously mentioned, use training=False as our model contains a BatchNormalization layer.\n",
        "\n",
        "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpR8HdyMhukJ"
      },
      "source": [
        "### \n",
        "# Compile the model before training it.\n",
        "# Since there are two classes, use a binary cross-entropy loss\n",
        "# with `from_logits=True` since the model provides a linear output.\n",
        "\n",
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ARiyMFsgbH"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krvBumovycVA"
      },
      "source": [
        "### \n",
        "# The 2.5M parameters in MobileNet are frozen,\n",
        "# but there are 1.2K _trainable_ parameters in the Dense layer.\n",
        "# These are divided between two `tf.Variable` objects, the weights and biases.\n",
        "\n",
        "len(model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om4O3EESkab1"
      },
      "source": [
        "#### Train the model\n",
        "### After training for 10 epochs, you should see ~94% accuracy on the validation set.\n",
        "\n",
        "initial_epochs = 10\n",
        "loss0, accuracy0 = model.evaluate(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cYT1c48CuSd"
      },
      "source": [
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsaRFlZ9B6WK"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=validation_dataset)\n",
        "\n",
        "# 1エポック60秒くらい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaMoB9vZ-jWK"
      },
      "source": [
        "### \n",
        "# Let's take a look at the learning curves of the training and validation accuracy/loss\n",
        "# when using the MobileNet V2 base model as a fixed feature extractor.\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53OTCh3jnbwV"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foWMyyUHbc1j"
      },
      "source": [
        "Note :\n",
        "- If you are wondering why the validation metrics are clearly better than the training metrics, the main factor is because layers like `tf.keras.layers.BatchNormalization` and `tf.keras.layers.Dropout` affect accuracy during training.\n",
        "  - They are turned off when calculating validation loss.\n",
        "\n",
        "- To a lesser extent, it is also because training metrics report the average for an epoch, while validation metrics are evaluated after the epoch, so validation metrics see a model that has trained slightly longer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o36tkk_DvVZC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqwV-CRdS6Nv"
      },
      "source": [
        "#### <font color = green> **1.4.** </font> Fine tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZcUkIOa-qn7"
      },
      "source": [
        "Note :\n",
        "- This should only be attempted after you have trained the top-level classifier with the pre-trained model set to non-trainable.\n",
        "- If you add a randomly initialized classifier on top of a pre-trained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) and your pre-trained model will forget what it has learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nzcagVitLQm"
      },
      "source": [
        "#### Un-freeze the top layers of the model\n",
        "# All you need to do is unfreeze the `base_model` and set the bottom layers to be un-trainable.\n",
        "# Then, you should recompile the model (necessary for these changes to take effect), and resume training.\n",
        "\n",
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4HgVAacRs5v"
      },
      "source": [
        "# Let's take a look to see how many layers are in the base model\n",
        "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 100\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "  layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtUnaz0WUDva"
      },
      "source": [
        "#### Compile the model\n",
        "# As you are training a much larger model and want to readapt the pretrained weights,\n",
        "# it is important to use a lower learning rate at this stage.\n",
        "# Otherwise, your model could overfit very quickly.\n",
        "\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer = tf.keras.optimizers.RMSprop(lr=base_learning_rate/10),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwBWy7J2kZvA"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNXelbMQtonr"
      },
      "source": [
        "len(model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECQLkAsFTlun"
      },
      "source": [
        "#### Continue training the model\n",
        "### If you trained to convergence earlier, this step will improve your accuracy by a few percentage points.\n",
        "\n",
        "fine_tune_epochs = 10\n",
        "total_epochs =  initial_epochs + fine_tune_epochs\n",
        "\n",
        "history_fine = model.fit(train_dataset,\n",
        "                         epochs=total_epochs,\n",
        "                         initial_epoch=history.epoch[-1],\n",
        "                         validation_data=validation_dataset)\n",
        "\n",
        "# 1エポック90秒前後"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpA8PlpQKygw"
      },
      "source": [
        "### After fine tuning the model nearly reaches 98% accuracy on the validation set.\n",
        "\n",
        "acc += history_fine.history['accuracy']\n",
        "val_acc += history_fine.history['val_accuracy']\n",
        "\n",
        "loss += history_fine.history['loss']\n",
        "val_loss += history_fine.history['val_loss']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chW103JUItdk"
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.ylim([0.8, 1])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "          plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.ylim([0, 1.0])\n",
        "plt.plot([initial_epochs-1,initial_epochs-1],\n",
        "         plt.ylim(), label='Start Fine Tuning')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KyNhagHwfar"
      },
      "source": [
        "#### Evaluation and prediction\n",
        "### Finaly you can verify the performance of the model on new data using test set.\n",
        "\n",
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print('Test accuracy :', accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUNoQNgtfNgt"
      },
      "source": [
        "### And now you are all set to use this model to predict if your pet is a cat or dog.\n",
        "\n",
        "#Retrieve a batch of images from the test set\n",
        "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
        "predictions = model.predict_on_batch(image_batch).flatten()\n",
        "\n",
        "# Apply a sigmoid since our model returns logits\n",
        "predictions = tf.nn.sigmoid(predictions)\n",
        "predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "print('Predictions:\\n', predictions.numpy())\n",
        "print('Labels:\\n', label_batch)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(9):\n",
        "  ax = plt.subplot(3, 3, i + 1)\n",
        "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
        "  plt.title(class_names[predictions[i]])\n",
        "  plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3sttX1zqFsb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0CsZ2bwvYm"
      },
      "source": [
        "### <font color = blue>**2.** </font> 公式チュートリアル　簡易版＆日本語解説\n",
        "\n",
        "https://note.nkmk.me/python-tensorflow-keras-transfer-learning-fine-tuning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMPi6xdrFhwE"
      },
      "source": [
        "#### <font color = green> **2.1.** </font> cifar10（Canadian Institute For Advanced Research）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbNuJ_EbyR6n"
      },
      "source": [
        "10種類の「物体カラー写真」（乗り物や動物など）の画像データセット\n",
        "- ラベル「0」： airplane（飛行機）\n",
        "- ラベル「1」： automobile（自動車）\n",
        "- ラベル「2」： bird（鳥）\n",
        "- ラベル「3」： cat（猫）\n",
        "- ラベル「4」： deer（鹿）\n",
        "- ラベル「5」： dog（犬）\n",
        "- ラベル「6」： frog（カエル）\n",
        "- ラベル「7」： horse（馬）\n",
        "- ラベル「8」： ship（船）\n",
        "- ラベル「9」： truck（トラック）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i4N78DZAX5d"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "# 2.1.0 -> 2.4.1@2021/03/04"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7uKIhTXAX0F"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(type(x_train))\n",
        "# <class 'numpy.ndarray'>\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "# (50000, 32, 32, 3) (50000, 1)\n",
        "\n",
        "print(x_test.shape, y_test.shape)\n",
        "# (10000, 32, 32, 3) (10000, 1)\n",
        "\n",
        "### 32×32 のRGBカラー画像が訓練用50000枚、テスト用10000枚。正解ラベルは0から9の整数。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gazoHFTeAXyL"
      },
      "source": [
        "### モデルの実装\n",
        "\n",
        "inputs = tf.keras.Input(shape=(None, None, 3))\n",
        "x = tf.keras.layers.Lambda(lambda img: tf.image.resize(img, (160, 160)))(inputs)\n",
        "x = tf.keras.layers.Lambda(tf.keras.applications.mobilenet_v2.preprocess_input)(x)\n",
        "\n",
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    weights='imagenet', input_tensor=x, input_shape=(160, 160, 3),\n",
        "    include_top=False, pooling='avg'\n",
        "    )\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [base_model,\n",
        "     tf.keras.layers.Dense(10, activation='softmax')]\n",
        "     )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "### ベースモデル（MobileNetV2の学習済みモデル）が一つのレイヤーとして扱われる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur1ljIj9AXwH"
      },
      "source": [
        "print(len(model.layers))\n",
        "# 2\n",
        "\n",
        "print(model.layers[0].name)\n",
        "# mobilenetv2_1.00_160\n",
        "\n",
        "print(len(model.layers[0].layers))\n",
        "# 158 -> 157"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYkZjNPqDunU"
      },
      "source": [
        "### 追加した全結合層のみを学習\n",
        "# ベースモデルのtrainable属性をFalseとし、Freeze（凍結）する\n",
        "# ベースモデルの各レイヤーの重みが更新されなくなる（＝ 学習されなくなる）\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM4WUECODulb"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBdUBHLcDujl"
      },
      "source": [
        "# 追加した全結合層はランダムな重みで初期化されているだけなので、当然、学習前のこの時点ではまったく分類できない\n",
        "# 参考までにevaluate()で評価してみると、正解率は10%前後となる\n",
        "# 10クラス分類なので適当に予測して偶然当たっているだけの正解率\n",
        "\n",
        "print(model.evaluate(x_test, y_test, verbose=0))\n",
        "# [loss value, metrics values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UCGv-HzASoK"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=6, validation_split=0.2, batch_size=256)\n",
        "### ColabのCPUだと1エポック14分半くらい。GPUだと20秒くらい\n",
        "\n",
        "print(model.evaluate(x_test, y_test, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gshtHwwSAJ0y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAcfY3TaAJyp"
      },
      "source": [
        "### 学習済みモデルの一部を再学習（ファインチューニング）\n",
        "# MobileNetV2はblock_1_xxxからblock_16_xxxまで16のブロックに分かれているが、ここではblock_12_xxx以降を再学習することにする\n",
        "# ブロック12の最初のレイヤーであるblock_12_expandのインデックス（何層目か）を取得する\n",
        "\n",
        "layer_names = [l.name for l in base_model.layers]\n",
        "idx = layer_names.index('block_12_expand')\n",
        "print(idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0PhKS4cAJwx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXQtjaN0Z6lB"
      },
      "source": [
        "# ベースモデルのtrainable属性をTrueとし、全体をUnfreeze（解凍）してから、\n",
        "# ブロック11までのレイヤー（block_12_expandの一つ前までのレイヤー）のtrainableをFalseとしFreeze（凍結）する\n",
        "\n",
        "base_model.trainable = True\n",
        "\n",
        "for layer in base_model.layers[:idx]:\n",
        "  layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYClPA3sZ6in"
      },
      "source": [
        "# なお、ベースモデルのtrainableをTrueとしないと、その内部のレイヤーのtrainableを\n",
        "# TrueとしてもUnfreeze（解凍）されず学習されないので注意\n",
        "# この例のようにベースモデルが一つのレイヤーとして扱われている場合、\n",
        "# ベースモデルのtrainableがFalseだと、内部のレイヤーのtrainableがTrueであっても学習対象とならない。\n",
        "\n",
        "# 上述のように、trainableを変更した後は再度compile()する必要がある\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEsUQVstZ6fg"
      },
      "source": [
        "# この状態で学習すると正解率がさらに改善することが確認できる\n",
        "\n",
        "model.fit(x_train, y_train, epochs=6, validation_split=0.2, batch_size=256)\n",
        "### ColabのCPUだと1エポック24分弱。GPUだと30秒かからないくらい\n",
        "\n",
        "print(model.evaluate(x_test, y_test, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6UzZrluZ6cO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ_EWBhaxjcm"
      },
      "source": [
        "#### <font color = green> **2.2.** </font> 犬猫画像分類"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTeiMprDyEFO"
      },
      "source": [
        "### データのダウンロード\n",
        "\n",
        "# 例として、以下の公式チュートリアルで紹介されている犬と猫の画像データを使用する。あくまでもお試し用なので枚数は多くない。\n",
        "# https://www.tensorflow.org/tutorials/images/classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBl_JdwMzOnd"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaL9rJMazOlf"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fncIZaPGzYp8"
      },
      "source": [
        "tf.random.set_seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LarlDUhMzOje"
      },
      "source": [
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    fname='cats_and_dogs_filtered.zip',\n",
        "    origin='https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip',\n",
        "    extract=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMPcfa_21_cq"
      },
      "source": [
        "- 以下のようなディレクトリ構造で、犬と猫の画像に分けられ、さらにtrainとvalidationに振り分けられている。\n",
        "\n",
        "```\n",
        "cats_and_dogs_filtered\n",
        "|__ train\n",
        "    |______ cats: [cat.0.jpg, cat.1.jpg, cat.2.jpg ....]\n",
        "    |______ dogs: [dog.0.jpg, dog.1.jpg, dog.2.jpg ...]\n",
        "|__ validation\n",
        "    |______ cats: [cat.2000.jpg, cat.2001.jpg, cat.2002.jpg ....]\n",
        "    |______ dogs: [dog.2000.jpg, dog.2001.jpg, dog.2002.jpg ...]\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AXbUFFc2IdH"
      },
      "source": [
        "- 公式チュートリアルではディレクトリ名の通り、訓練データと検証（validation）データとして使っているが、以下のサンプルコードではtrainを訓練データと検証データ、validationをテストデータとして使う。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-maVe_qzOfH"
      },
      "source": [
        "path_to_dir = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(path_to_dir, 'train')\n",
        "test_dir = os.path.join(path_to_dir, 'validation')\n",
        "\n",
        "### tf.keras.utils.get_file() はダウンロード先のディレクトリのパスを返す。\n",
        "### そこから train, validation の各ディレクトリへのパス文字列を生成する。"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JXoapERyEC2"
      },
      "source": [
        "### データの準備 : ImageDataGenerator\n",
        "\n",
        "# まず ImageDataGenerator のインスタンスを生成する。\n",
        "# 引数 preprocessing_function に前処理を行う関数、ここでは MobileNetV2 の\n",
        "# 前処理関数 preprocess_input を指定する。\n",
        "# 訓練データの方は訓練用と検証用に分割するため引数 validation_split を指定する\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    validation_split=0.2\n",
        "    )\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "    )\n",
        "\n",
        "# Data Augmentation（画像の水増し）を行う場合はその他の引数を設定するが、今回は行わない\n",
        "# なお、validation_split を設定した場合、訓練用と検証用の両方に対して\n",
        "# Data Augmentation が行われるので注意"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdVpoReO0Alv"
      },
      "source": [
        "# 訓練用、検証用、テスト用の各ジェネレータイテレータを flow_from_directory() メソッドで生成する\n",
        "# 訓練用と検証用は引数 subset をそれぞれ 'training', 'validation' とする\n",
        "# また、引数 target_size に画像のサイズを設定するとリサイズされる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8pjX7wT0AhZ"
      },
      "source": [
        "batch_size = 64\n",
        "height = 160\n",
        "width = 160"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYuuiEgM0AfD"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    target_size=(height, width),\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GauSXMKA0Abx"
      },
      "source": [
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=train_dir,\n",
        "    target_size=(height, width),\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ9utBH40AZI"
      },
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    batch_size=batch_size,\n",
        "    directory=test_dir,\n",
        "    target_size=(height, width),\n",
        "    class_mode='binary'\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGODR-APyEAs"
      },
      "source": [
        "### モデルの実装と学習\n",
        "# MobileNetV2 の学習済みモデルをベースモデルとして使う\n",
        "# リサイズを含む前処理は ImageDataGenerator の設定で行っているため\n",
        "# ここでは input_shape を設定するのみ\n",
        "\n",
        "base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
        "    weights='imagenet', input_shape=(height, width, 3),\n",
        "    include_top=False, pooling='avg'\n",
        "    )\n",
        "\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=base_model.input, outputs=x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ouxi8-_1Pyz"
      },
      "source": [
        "# Sequential API でモデルを生成してもいいが、参考までにここでは Functional API を用いる\n",
        "# Sequential API ではベースモデルが一つのレイヤーとして扱われるが\n",
        "# Functional API の場合はそのような入れ子の形にはならない\n",
        "\n",
        "print(len(model.layers))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0ww-VBKZ6aL"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggA0SQImAJs1"
      },
      "source": [
        "# 入れ子構造ではないが、base_model の各レイヤーと\n",
        "# 新たに構築した model の各レイヤーは同じオブジェクトを指している\n",
        "# base_model の trainable を変更すると、その中の各レイヤーの trainable も変更されるため\n",
        "# Sequential API での例と同じく一括で設定可能\n",
        "\n",
        "print(model.layers[0] is base_model.layers[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17wqgIkm4kQ0"
      },
      "source": [
        "print(base_model.layers[0].trainable)\n",
        "print(model.layers[0].trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU8K1EKc1ZWY"
      },
      "source": [
        "base_model.trainable = False\n",
        "\n",
        "print(base_model.layers[0].trainable)\n",
        "print(model.layers[0].trainable)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4St1mRR1ZKC"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffeZo9ym1ZHm"
      },
      "source": [
        "# 新たに追加した全結合層の学習前にモデルを評価すると正解率は50%程度\n",
        "# 2クラス分類なので、まったく分類できていないことが確認できる\n",
        "\n",
        "print(model.evaluate(test_generator, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3IsDgk21ZFi"
      },
      "source": [
        "# ImageDataGenerator は無限にイテレーションするので\n",
        "# 引数 steps_per_epoch および validation_steps を明示的に設定する\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.n // batch_size,\n",
        "    epochs=6\n",
        "    )\n",
        "\n",
        "# 1エポック10秒くらい@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8C61eB-1ZDB"
      },
      "source": [
        "print(model.evaluate(test_generator, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoJiKzK_1ZAL"
      },
      "source": [
        "# ファインチューニングのために、ベースモデルの後半のレイヤーの trainable を True とする\n",
        "# trainable を変更したあとは忘れずに compile()\n",
        "\n",
        "idx = [l.name for l in base_model.layers].index('block_12_expand')\n",
        "\n",
        "for layer in base_model.layers[idx:]:\n",
        "  layer.trainable = True\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gKxIRr55ktO"
      },
      "source": [
        "# base_model の trainable は False のままだが\n",
        "# ベースモデルが一つのレイヤーとして扱われていないので\n",
        "# ベースモデルの trainable の値によらず内部のレイヤーの trainable の値が反映される\n",
        "\n",
        "# ベースモデルの trainable を変更するとその中のレイヤーの trainable も一括で変更されるので\n",
        "# ベースモデルの trainable を True にしてから前半のレイヤーの trainable を False にしても同じ結果になる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7XEyHkS1xFE"
      },
      "source": [
        "# 再学習を行う\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=valid_generator.n // batch_size,\n",
        "    epochs=6\n",
        "    )\n",
        "\n",
        "# 1エポック10秒くらい@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8jwd8K01xDB"
      },
      "source": [
        "print(model.evaluate(test_generator, verbose=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0impqe0v1xAy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6TC1go86i68"
      },
      "source": [
        "### <font color = blue>**3.** </font> データ拡張（Data Augmentation）の詳解含む公式サンプルコード"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj-k2OfYIwKs"
      },
      "source": [
        "Transfer learning & fine-tuning\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2020/04/15<br>\n",
        "**Last modified:** 2020/05/12<br>\n",
        "**Description:** Complete guide to transfer learning & fine-tuning in Keras.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oulGtWoIwK3"
      },
      "source": [
        "## Setup\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYTk3Ahf9u67"
      },
      "source": [
        "#### <font color = green> **3.1.** </font> Freezing layers: understanding the `trainable` attribute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUyLX679IwLM"
      },
      "source": [
        "# Example: the `Dense` layer has 2 trainable weights (kernel & bias)\n",
        "\n",
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))  # Create the weights\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gfIPKkdIwLW"
      },
      "source": [
        "# Example: the `BatchNormalization` layer has 2 trainable weights and 2 non-trainable weights\n",
        "# It uses non-trainable weights to keep track of the mean and variance of its inputs during training.\n",
        "\n",
        "layer = keras.layers.BatchNormalization()\n",
        "layer.build((None, 4))  # Create the weights\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_AhPdaRIwLW"
      },
      "source": [
        "layer = keras.layers.Dense(3)\n",
        "layer.build((None, 4))  # Create the weights\n",
        "layer.trainable = False  # Freeze the layer\n",
        "\n",
        "print(\"weights:\", len(layer.weights))\n",
        "print(\"trainable_weights:\", len(layer.trainable_weights))\n",
        "print(\"non_trainable_weights:\", len(layer.non_trainable_weights))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liRGk1NSIwLX"
      },
      "source": [
        "### When a trainable weight becomes non-trainable, its value is no longer updated during training.\n",
        " \n",
        "# Make a model with 2 layers\n",
        "layer1 = keras.layers.Dense(3, activation=\"relu\")\n",
        "layer2 = keras.layers.Dense(3, activation=\"sigmoid\")\n",
        "model = keras.Sequential([keras.Input(shape=(3,)), layer1, layer2])\n",
        "\n",
        "# Freeze the first layer\n",
        "layer1.trainable = False\n",
        "\n",
        "# Keep a copy of the weights of layer1 for later reference\n",
        "initial_layer1_weights_values = layer1.get_weights()\n",
        "\n",
        "# Train the model\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "model.fit(np.random.random((2, 3)), np.random.random((2, 3)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992hTv2-8xcb"
      },
      "source": [
        "# Check that the weights of layer1 have not changed during training\n",
        "final_layer1_weights_values = layer1.get_weights()\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[0], final_layer1_weights_values[0]\n",
        "    )\n",
        "np.testing.assert_allclose(\n",
        "    initial_layer1_weights_values[1], final_layer1_weights_values[1]\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97MmSK7lIwLZ"
      },
      "source": [
        "# If you set `trainable = False` on a model or on any layer that has sublayers,\n",
        "# all children layers become non-trainable as well.\n",
        "\n",
        "inner_model = keras.Sequential(\n",
        "    [\n",
        "     keras.Input(shape=(3,)),\n",
        "     keras.layers.Dense(3, activation=\"relu\"),\n",
        "     keras.layers.Dense(3, activation=\"relu\"),\n",
        "     ]\n",
        "     )\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [keras.Input(shape=(3,)), inner_model, keras.layers.Dense(3, activation=\"sigmoid\"),]\n",
        "    )\n",
        "\n",
        "model.trainable = False  # Freeze the outer model\n",
        "\n",
        "assert inner_model.trainable == False  # All layers in `model` are now frozen\n",
        "assert inner_model.layers[0].trainable == False  # `trainable` is propagated recursively"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHoFqTqEIwLZ"
      },
      "source": [
        "#### <font color = green> **3.2.** </font> The typical transfer-learning workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-9LDn1NLtP_"
      },
      "source": [
        "Here's what the first workflow looks like in Keras:\n",
        "\n",
        "First, instantiate a base model with pre-trained weights.\n",
        "\n",
        "```python\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU0XeOz_Lqfu"
      },
      "source": [
        "Then, freeze the base model.\n",
        "\n",
        "```python\n",
        "base_model.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SwqgmdMLUPt"
      },
      "source": [
        "Create a new model on top.\n",
        "\n",
        "```python\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "# We make sure that the base_model is running in inference mode here,\n",
        "# by passing `training=False`. This is important for fine-tuning, as you will\n",
        "# learn in a few paragraphs.\n",
        "x = base_model(inputs, training=False)\n",
        "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "# A Dense classifier with a single unit (binary classification)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KamHgFtcLT5g"
      },
      "source": [
        "Train the model on new data.\n",
        "\n",
        "```python\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])\n",
        "model.fit(new_dataset, epochs=20, callbacks=..., validation_data=...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjPQR56RIwLg"
      },
      "source": [
        "#### <font color = green> **3.3.** </font> Fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeUun5B8ME7v"
      },
      "source": [
        "This is how to implement fine-tuning of the whole base model:\n",
        "\n",
        "```python\n",
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# It's important to recompile your model after you make any changes\n",
        "# to the `trainable` attribute of any inner layer, so that your changes\n",
        "# are take into account\n",
        "model.compile(optimizer=keras.optimizers.Adam(1e-5),  # Very low learning rate\n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "# Train end-to-end. Be careful to stop before you overfit!\n",
        "model.fit(new_dataset, epochs=10, callbacks=..., validation_data=...)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDKQzMTFMEzH"
      },
      "source": [
        "**Important note about `compile()` and `trainable`**\n",
        "\n",
        "Calling `compile()` on a model is meant to \"freeze\" the behavior of that model. \\\n",
        "This implies that the `trainable` attribute values at the time the model is compiled should be preserved throughout the lifetime of that model, until `compile` is called again. \\\n",
        "Hence, if you change any `trainable` value, make sure to call `compile()` again on your model for your changes to be taken into account."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faCR2C_oMEog"
      },
      "source": [
        "**Important notes about `BatchNormalization` layer**\n",
        "\n",
        "Many image models contain `BatchNormalization` layers. That layer is a special case on\n",
        " every imaginable count. Here are a few things to keep in mind.\n",
        "\n",
        "- `BatchNormalization` contains 2 non-trainable weights that get updated during training.\n",
        "  - These are the variables tracking the mean and variance of the inputs.\n",
        "- When you set `bn_layer.trainable = False`, the `BatchNormalization` layer will run in inference mode, and will not update its mean & variance statistics.\n",
        "  - This is not the case for other layers in general, as\n",
        "[weight trainability & inference/training modes are two orthogonal concepts](\n",
        "  https://keras.io/getting_started/faq/#whats-the-difference-between-the-training-argument-in-call-and-the-trainable-attribute).\n",
        "  - But the two are tied in the case of the `BatchNormalization` layer.\n",
        "- When you unfreeze a model that contains `BatchNormalization` layers in order to do fine-tuning, you should keep the `BatchNormalization` layers in inference mode by passing `training=False` when calling the base model.\n",
        "  - Otherwise the updates applied to the non-trainable weights will suddenly destroy what the model has learned."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1um4PyCMDhO"
      },
      "source": [
        "You'll see this pattern in action in the end-to-end example at the end of this guide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9IeUQK8IwLj"
      },
      "source": [
        "#### <font color = green> **3.4.** </font> Transfer learning & fine-tuning with a custom training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xq15vzvNP5z"
      },
      "source": [
        "If instead of `fit()`, you are using your own low-level training loop, the workflow stays essentially the same. \\\n",
        "You should be careful to only take into account the list `model.trainable_weights` when applying gradient updates:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zmcna-9lNKtG"
      },
      "source": [
        "```python\n",
        "# Create base model\n",
        "base_model = keras.applications.Xception(\n",
        "    weights='imagenet',\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False)\n",
        "# Freeze base model\n",
        "base_model.trainable = False\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5vVjvJFNhRm"
      },
      "source": [
        "```python\n",
        "# Create new model on top.\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "optimizer = keras.optimizers.Adam()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtIQa-T9NdsT"
      },
      "source": [
        "```python\n",
        "# Iterate over the batches of a dataset.\n",
        "for inputs, targets in new_dataset:\n",
        "    # Open a GradientTape.\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Forward pass.\n",
        "        predictions = model(inputs)\n",
        "        # Compute the loss value for this batch.\n",
        "        loss_value = loss_fn(targets, predictions)\n",
        "\n",
        "    # Get gradients of loss wrt the *trainable* weights.\n",
        "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
        "    # Update the weights of the model.\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsUcbfjWIwLk"
      },
      "source": [
        "Likewise for fine-tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgsbCXf6IwLk"
      },
      "source": [
        "#### <font color = green> **3.5.** </font> An end-to-end example: fine-tuning an image classification model on a cats vs. dogs dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ygQC4sIIwLk"
      },
      "source": [
        "#### Getting the data\n",
        "# To keep our dataset small, we will use 40% of the original training data (25,000 images)\n",
        "#  for training, 10% for validation, and 10% for testing.\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    # Reserve 10% for validation and 10% for test\n",
        "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
        "    as_supervised=True,  # Include labels\n",
        ")\n",
        "\n",
        "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
        "print(\n",
        "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",
        ")\n",
        "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))\n",
        "\n",
        "### These are the first 9 images in the training dataset -- as you can see, they're all different sizes."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ogrQMY5IwLl"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i, (image, label) in enumerate(train_ds.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title(int(label))\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "### We can also see that label 1 is \"dog\" and label 0 is \"cat\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6GHiO2gIwLm"
      },
      "source": [
        "#### Standardizing the data\n",
        "# each pixel consists of 3 integer values between 0 and 255 (RGB level values).\n",
        "# - Standardize to a fixed image size. We pick 150x150.\n",
        "# - Normalize pixel values between -1 and 1.\n",
        "\n",
        "size = (150, 150)\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
        "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcsroZ9cIwLm"
      },
      "source": [
        "### Besides, let's batch the data and use caching & prefetching to optimize loading speed.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsoif3ffIwLp"
      },
      "source": [
        "#### Using random data augmentation\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "     layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "     ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLohdgsrIwLq"
      },
      "source": [
        "### Let's visualize what the first image of the first batch looks like after various random transformations:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  first_image = images[0]\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    augmented_image = data_augmentation(\n",
        "        tf.expand_dims(first_image, 0), training=True\n",
        "        )\n",
        "    plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
        "    plt.title(int(labels[i]))\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TbAqxLjIwLr"
      },
      "source": [
        "### Build a model\n",
        "# Note that:\n",
        "# - We add a `Normalization` layer to scale input values (initially in the `[0, 255]` range) to the `[-1, 1]` range.\n",
        "# - We add a `Dropout` layer before the classification layer, for regularization.\n",
        "# - We make sure to pass `training=False` when calling the base model, so that it runs in inference mode,\n",
        "#     so that batchnorm statistics don't get updated even after we unfreeze the base model for fine-tuning.\n",
        "\n",
        "base_model = keras.applications.Xception(\n",
        "    weights=\"imagenet\",  # Load weights pre-trained on ImageNet.\n",
        "    input_shape=(150, 150, 3),\n",
        "    include_top=False,\n",
        ")  # Do not include the ImageNet classifier at the top."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkjWN577_cPr"
      },
      "source": [
        "# Freeze the base_model\n",
        "base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uuvlRsZ_edt"
      },
      "source": [
        "# Create new model on top\n",
        "inputs = keras.Input(shape=(150, 150, 3))\n",
        "x = data_augmentation(inputs)  # Apply random data augmentation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OE8w83T_ebo"
      },
      "source": [
        "# Pre-trained Xception weights requires that input be normalized\n",
        "# from (0, 255) to a range (-1., +1.), the normalization layer\n",
        "# does the following, outputs = (inputs - mean) / sqrt(var)\n",
        "norm_layer = keras.layers.experimental.preprocessing.Normalization()\n",
        "mean = np.array([127.5] * 3)\n",
        "var = mean ** 2\n",
        "# Scale inputs to [-1, +1]\n",
        "x = norm_layer(x)\n",
        "norm_layer.set_weights([mean, var])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw-efyjk_eZk"
      },
      "source": [
        "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
        "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
        "# base_model is running in inference mode here.\n",
        "x = base_model(x, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGlqmymnIwLr"
      },
      "source": [
        "### Train the top layer\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        "    )\n",
        "\n",
        "epochs = 20\n",
        "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)\n",
        "\n",
        "# 1stエポックだけ1分、以降1エポック30秒かからないくらい@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0SM0ZS_AEBf"
      },
      "source": [
        "#### <font color = green> **3.6.** </font> Do a round of fine-tuning of the entire model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhtfOEWfIwLv"
      },
      "source": [
        "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
        "# since we passed `training=False` when calling it. This means that\n",
        "# the batchnorm layers will not update their batch statistics.\n",
        "# This prevents the batchnorm layers from undoing all the training\n",
        "# we've done so far.\n",
        "\n",
        "base_model.trainable = True\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiJcsDQzOSsl"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        "    )\n",
        "\n",
        "epochs = 3  ###\n",
        "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)\n",
        "\n",
        "### After 10 epochs, fine-tuning gains us a nice improvement here.\n",
        "# 1エポック2分かからないくらい@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqsnBRqQwEf8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkGzLvSA6Jwm"
      },
      "source": [
        "### <font color = blue>**4.** </font> EfficientNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8xlGFs2KwRp"
      },
      "source": [
        "[EfficientNetを最速で試す方法](https://qiita.com/wakame1367/items/d90fa56bd9d11c4db50e)\n",
        "\n",
        "[Qiita - 2019年最強の画像認識モデルEfficientNet解説](https://qiita.com/omiita/items/83643f78baabfa210ab1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_p0LFBLTIIq"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DplLsQs-TTdq"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ama5oCGAUcHl"
      },
      "source": [
        "### TensorFlow flowers データセットを利用\n",
        "# このデータをモデルにロードするには tf.keras.preprocessing.image.ImageDataGenerator を使うのがもっとも簡単な方法\n",
        "# すべての TensorFlow Hub の画像モジュールは [0, 1] の範囲で float で入力されることを想定しています\n",
        "# 入力をリスケールする際には ImageDataGenerator の rescale パラメータを利用してください\n",
        "# 画像のサイズは後ほど処理されます\n",
        "\n",
        "data_root = tf.keras.utils.get_file(\n",
        "    'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
        "    untar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFQjPzjoUeRA"
      },
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "\n",
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n",
        "image_data = image_generator.flow_from_directory(str(data_root), target_size=IMAGE_SHAPE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fyiMbDELxOT"
      },
      "source": [
        "# クラス数はデータに合わせて適当に変えてください\n",
        "# num_classes = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUjWQLscVoMe"
      },
      "source": [
        "### 結果のオブジェクトは image_batch, label_batch のペアを返すイテレーターです\n",
        "\n",
        "for image_batch, label_batch in image_data:\n",
        "  print(\"Image batch shape: \", image_batch.shape)\n",
        "  print(\"Label batch shape: \", label_batch.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8-eoRrrTWVQ"
      },
      "source": [
        "# URLはこちらのページ https://tfhub.dev/google/collections/efficientnet/1\n",
        "# 末尾に記載されているURLから使いたいモデル(B0-B7)までのどれかを選んでください\n",
        "# 今回はB0を使います\n",
        "\n",
        "feature_extractor_url = \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOqMvu4dULTn"
      },
      "source": [
        "# 特徴抽出器 (feature extractor) を作成します\n",
        "# width/heightについてはB0は(224, 224)が推奨とされているのでそうしています\n",
        "# 推奨のwidth/heightについてはこちらのページをご覧ください https://tfhub.dev/google/collections/efficientnet/1\n",
        "\n",
        "feature_extractor_layer = hub.KerasLayer(feature_extractor_url,\n",
        "                                         input_shape=(224,224,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of7i-35F09ls"
      },
      "source": [
        "# これは画像毎に長さ 1280 のベクトルデータを返します\n",
        "\n",
        "feature_batch = feature_extractor_layer(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEOe5thLUO2s"
      },
      "source": [
        "# 学習済み重みは固定\n",
        "# 訓練が新しい分類器のレイヤーのみを変更するようにします\n",
        "\n",
        "feature_extractor_layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23iLHIieUT0B"
      },
      "source": [
        "# Keras functional APIで動くかなと試したのですがうまく動かず\n",
        "# 公式Tutorialに倣って以下の通りにしています\n",
        "# hub レイヤーをラップして、新しい分類層を追加\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [feature_extractor_layer,\n",
        "     layers.Dense(image_data.num_classes, activation='softmax')\n",
        "     ])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7X-fDS3zUWvd"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbf3c7aDUv8c"
      },
      "source": [
        "# 訓練のプロセスを可視化するために、各エポックの平均だけではなく各々のバッチで\n",
        "# 個別に損失と正確度を記録するためのカスタムコールバックを使用\n",
        "\n",
        "class CollectBatchStats(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    self.batch_losses = []\n",
        "    self.batch_acc = []\n",
        "\n",
        "  def on_train_batch_end(self, batch, logs=None):\n",
        "    self.batch_losses.append(logs['loss'])\n",
        "    self.batch_acc.append(logs['acc'])\n",
        "    self.model.reset_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiMzP4bvU0Lx"
      },
      "source": [
        "epochs = 10\n",
        "steps_per_epoch = np.ceil(image_data.samples/image_data.batch_size)\n",
        "\n",
        "batch_stats_callback = CollectBatchStats()\n",
        "\n",
        "history = model.fit(image_data, epochs=epochs,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    callbacks = [batch_stats_callback],\n",
        "                    )\n",
        "# 1エポック15秒くらい@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9anFOkcU2QB"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,2])\n",
        "plt.plot(batch_stats_callback.batch_losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc-Gg1j2VM7Q"
      },
      "source": [
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Training Steps\")\n",
        "plt.ylim([0,1])\n",
        "plt.plot(batch_stats_callback.batch_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2XTR79oVVub"
      },
      "source": [
        "### 推論結果の確認\n",
        "# 前からプロットをやり直すには、まずクラス名のリストを取得\n",
        "\n",
        "class_names = sorted(image_data.class_indices.items(), key=lambda pair:pair[1])\n",
        "class_names = np.array([key.title() for key, value in class_names])\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTFzR-DAVaNs"
      },
      "source": [
        "# 画像のバッチをモデルに入力し、得られた ID をクラス名に変換\n",
        "\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_id = np.argmax(predicted_batch, axis=-1)\n",
        "predicted_label_batch = class_names[predicted_id]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcfI3I7LVskO"
      },
      "source": [
        "# 結果をプロット\n",
        "\n",
        "label_id = np.argmax(label_batch, axis=-1)\n",
        "\n",
        "plt.figure(figsize=(10,9))\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for n in range(30):\n",
        "  plt.subplot(6,5,n+1)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"green\" if predicted_id[n] == label_id[n] else \"red\"\n",
        "  plt.title(predicted_label_batch[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LPwzLxBavuI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jl7Gj3Its6z"
      },
      "source": [
        "### <font color = blue>**5.** </font> Fine-tuning a BERT model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXLA5InzXydn"
      },
      "source": [
        "- Copyright 2019 The TensorFlow Authors.\n",
        "- Licensed under the Apache License, Version 2.0 (the \"License\")\n",
        "- In this example, we will work through fine-tuning a BERT model using the tensorflow-models PIP package.\n",
        "- The pretrained BERT model this tutorial is based on is also available on [TensorFlow Hub](https://tensorflow.org/hub), to see how to use it refer to the [Hub Appendix](#hub_bert)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2d9S2CSSO1z"
      },
      "source": [
        "#### <font color = green> **5.1.** </font> Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvNr2svBM-p3"
      },
      "source": [
        "### Install the TensorFlow Model Garden pip package\n",
        "# `tf-models-official` is the stable Model Garden package.\n",
        "# Note that it may not include the latest changes in the `tensorflow_models` github repo.\n",
        "# To include latest changes, you may install `tf-models-nightly`, which is the nightly Model Garden package created daily automatically.\n",
        "# pip will install all models and dependencies automatically.\n",
        "\n",
        "!pip install -q tf-models-official==2.4.0\n",
        "#!pip install -q tf-models-official\n",
        "#!pip install tensorflow-text\n",
        "#!pip install tf-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXsXev5MNr20"
      },
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from official.modeling import tf_utils\n",
        "from official import nlp\n",
        "from official.nlp import bert\n",
        "\n",
        "# Load the required submodules\n",
        "import official.nlp.optimization\n",
        "import official.nlp.bert.bert_models\n",
        "import official.nlp.bert.configs\n",
        "import official.nlp.bert.run_classifier\n",
        "import official.nlp.bert.tokenization\n",
        "import official.nlp.data.classifier_data_lib\n",
        "import official.nlp.modeling.losses\n",
        "import official.nlp.modeling.models\n",
        "import official.nlp.modeling.networks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzRHOLciR8eq"
      },
      "source": [
        "# Resources \n",
        "# This directory contains the configuration, vocabulary, and a pre-trained checkpoint used in this tutorial:\n",
        "\n",
        "gs_folder_bert = \"gs://cloud-tpu-checkpoints/bert/v3/uncased_L-12_H-768_A-12\"\n",
        "tf.io.gfile.listdir(gs_folder_bert)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0dAkUttJAzj"
      },
      "source": [
        "# You can get a pre-trained BERT encoder from TensorFlow Hub\n",
        "\n",
        "hub_url_bert = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv6abtRvH4xO"
      },
      "source": [
        "#### <font color = green> **5.2.** </font> The data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28DvUhC1YUiB"
      },
      "source": [
        "For this example we used the [GLUE MRPC dataset from TFDS](https://www.tensorflow.org/datasets/catalog/glue#gluemrpc).\n",
        "\n",
        "This dataset is not set up so that it can be directly fed into the BERT model, so this section also handles the necessary preprocessing.\n",
        "\n",
        "Get the dataset from TensorFlow Datasets\n",
        "\n",
        "The Microsoft Research Paraphrase Corpus (Dolan & Brockett, 2005) is a corpus of sentence pairs automatically extracted from online news sources, with human annotations for whether the sentences in the pair are semantically equivalent.\n",
        "\n",
        "*   Number of labels: 2.\n",
        "*   Size of training dataset: 3668.\n",
        "*   Size of evaluation dataset: 408.\n",
        "*   Maximum sequence length of training and evaluation dataset: 128.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ijikx5OsH9AT"
      },
      "source": [
        "glue, info = tfds.load('glue/mrpc', with_info=True,\n",
        "                       # It's small, load the whole dataset\n",
        "                       batch_size=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf9zz4vLYXjr"
      },
      "source": [
        "list(glue.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQrHxv7W7jH5"
      },
      "source": [
        "# The `info` object describes the dataset and it's features:\n",
        "\n",
        "info.features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0gfc_VTayfQ"
      },
      "source": [
        "# The two classes are:\n",
        "\n",
        "info.features['label'].names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xON_i6SkwApW"
      },
      "source": [
        "# Here is one example from the training set:\n",
        "\n",
        "glue_train = glue['train']\n",
        "\n",
        "for key, value in glue_train.items():\n",
        "  print(f\"{key:9s}: {value[0].numpy()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fbTyfJpNr7x"
      },
      "source": [
        "#### <font color = green> **5.3.** </font> The BERT tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idxyhmrCQcw5"
      },
      "source": [
        "# Set up tokenizer to generate Tensorflow dataset\n",
        "tokenizer = bert.tokenization.FullTokenizer(\n",
        "    vocab_file=os.path.join(gs_folder_bert, \"vocab.txt\"),\n",
        "    do_lower_case=True)\n",
        "\n",
        "print(\"Vocab size:\", len(tokenizer.vocab))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_OfOYPg853R"
      },
      "source": [
        "# Tokenize a sentence:\n",
        "tokens = tokenizer.tokenize(\"Hello TensorFlow!\")\n",
        "print(tokens)\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "print(ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkAXLtuyWWDI"
      },
      "source": [
        "#### <font color = green> **5.4.** </font> Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdL-dRNRBRJT"
      },
      "source": [
        "# Encode the sentences\n",
        "# The model expects its two inputs sentences to be concatenated together.\n",
        "# This input is expected to start with a `[CLS]` \"This is a classification problem\" token,\n",
        "# and each sentence should end with a `[SEP]` \"Separator\" token:\n",
        "\n",
        "tokenizer.convert_tokens_to_ids(['[CLS]', '[SEP]'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR7BmtU498Bh"
      },
      "source": [
        "# Start by encoding all the sentences while appending a `[SEP]` token,\n",
        "# and packing them into ragged-tensors:\n",
        "\n",
        "def encode_sentence(s):\n",
        "  tokens = list(tokenizer.tokenize(s.numpy()))\n",
        "  tokens.append('[SEP]')\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "sentence1 = tf.ragged.constant(\n",
        "    [encode_sentence(s) for s in glue_train[\"sentence1\"]])\n",
        "sentence2 = tf.ragged.constant(\n",
        "    [encode_sentence(s) for s in glue_train[\"sentence2\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "has42aUdfky-"
      },
      "source": [
        "print(\"Sentence1 shape:\", sentence1.shape.as_list())\n",
        "print(\"Sentence2 shape:\", sentence2.shape.as_list())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USD8uihw-g4J"
      },
      "source": [
        "# Now prepend a `[CLS]` token, and concatenate the ragged tensors to form\n",
        "# a single `input_word_ids` tensor for each example.\n",
        "# `RaggedTensor.to_tensor()` zero pads to the longest sequence.\n",
        "\n",
        "cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
        "input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
        "_ = plt.pcolormesh(input_word_ids.to_tensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EezOO9qj91kP"
      },
      "source": [
        "# Mask and input type\n",
        "# The mask allows the model to cleanly differentiate between the content and the padding.\n",
        "# The mask has the same shape as the `input_word_ids`,\n",
        "# and contains a `1` anywhere the `input_word_ids` is not padding.\n",
        "\n",
        "input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
        "\n",
        "plt.pcolormesh(input_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CetH_5C9P2m"
      },
      "source": [
        "# The \"input type\" also has the same shape, but inside the non-padded region,\n",
        "# contains a `0` or a `1` indicating which sentence the token is a part of. \n",
        "\n",
        "type_cls = tf.zeros_like(cls)\n",
        "type_s1 = tf.zeros_like(sentence1)\n",
        "type_s2 = tf.ones_like(sentence2)\n",
        "input_type_ids = tf.concat([type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
        "\n",
        "plt.pcolormesh(input_type_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDGiWYPLEd5a"
      },
      "source": [
        "# Put it all together\n",
        "# Collect the above text parsing code into a single function,\n",
        "# and apply it to each split of the `glue/mrpc` dataset.\n",
        "\n",
        "def encode_sentence(s, tokenizer):\n",
        "  tokens = list(tokenizer.tokenize(s))\n",
        "  tokens.append('[SEP]')\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "def bert_encode(glue_dict, tokenizer):\n",
        "  num_examples = len(glue_dict[\"sentence1\"])\n",
        "  sentence1 = tf.ragged.constant(\n",
        "      [encode_sentence(s, tokenizer) for s in np.array(glue_dict[\"sentence1\"])])\n",
        "  sentence2 = tf.ragged.constant(\n",
        "      [encode_sentence(s, tokenizer) for s in np.array(glue_dict[\"sentence2\"])])\n",
        "\n",
        "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
        "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
        "\n",
        "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
        "\n",
        "  type_cls = tf.zeros_like(cls)\n",
        "  type_s1 = tf.zeros_like(sentence1)\n",
        "  type_s2 = tf.ones_like(sentence2)\n",
        "  input_type_ids = tf.concat(\n",
        "      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
        "\n",
        "  inputs = {'input_word_ids': input_word_ids.to_tensor(),\n",
        "            'input_mask': input_mask,\n",
        "            'input_type_ids': input_type_ids}\n",
        "\n",
        "  return inputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuLKxf6zHxw-"
      },
      "source": [
        "glue_train = bert_encode(glue['train'], tokenizer)\n",
        "glue_train_labels = glue['train']['label']\n",
        "\n",
        "glue_validation = bert_encode(glue['validation'], tokenizer)\n",
        "glue_validation_labels = glue['validation']['label']\n",
        "\n",
        "glue_test = bert_encode(glue['test'], tokenizer)\n",
        "glue_test_labels  = glue['test']['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyjTdGpFhO_1"
      },
      "source": [
        "# Each subset of the data has been converted to a dictionary of features,\n",
        "# and a set of labels.\n",
        "# Each feature in the input dictionary has the same shape,\n",
        "# and the number of labels should match:\n",
        "\n",
        "for key, value in glue_train.items():\n",
        "  print(f'{key:15s} shape: {value.shape}')\n",
        "\n",
        "print(f'glue_train_labels shape: {glue_train_labels.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwymsbkbLDA"
      },
      "source": [
        "#### <font color = green> **5.5.** </font> The model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujapVfZ_AKW7"
      },
      "source": [
        "# Build the model\n",
        "# The first step is to download the configuration  for the pre-trained model.\n",
        "\n",
        "import json\n",
        "\n",
        "bert_config_file = os.path.join(gs_folder_bert, \"bert_config.json\")\n",
        "config_dict = json.loads(tf.io.gfile.GFile(bert_config_file).read())\n",
        "\n",
        "bert_config = bert.configs.BertConfig.from_dict(config_dict)\n",
        "\n",
        "config_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH682__U0FBv"
      },
      "source": [
        "# The `config` defines the core BERT Model, which is a Keras model to predict\n",
        "# the outputs of `num_classes` from the inputs with maximum sequence length `max_seq_length`.\n",
        "# This function returns both the encoder and the classifier.\n",
        "\n",
        "bert_classifier, bert_encoder = bert.bert_models.classifier_model(\n",
        "    bert_config, num_labels=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAQblMIjwkvx"
      },
      "source": [
        "# The classifier has three inputs and one output:\n",
        "\n",
        "tf.keras.utils.plot_model(bert_classifier, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTjgPbp4ZDKo"
      },
      "source": [
        "# Run it on a test batch of data 10 examples from the training set.\n",
        "# The output is the logits for the two classes:\n",
        "\n",
        "glue_batch = {key: val[:10] for key, val in glue_train.items()}\n",
        "\n",
        "bert_classifier(glue_batch, training=True).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L__-erBwLIQ"
      },
      "source": [
        "# The `TransformerEncoder` in the center of the classifier above **is** the `bert_encoder`.\n",
        "# Inspecting the encoder, we see its stack of `Transformer` layers connected to those same three inputs:\n",
        "\n",
        "tf.keras.utils.plot_model(bert_encoder, show_shapes=True, dpi=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97Ll2Gichd_Y"
      },
      "source": [
        "# Restore the encoder weights when built the encoder is randomly initialized.\n",
        "# Restore the encoder's weights from the checkpoint:\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(encoder=bert_encoder)\n",
        "checkpoint.read(\n",
        "    os.path.join(gs_folder_bert, 'bert_model.ckpt')).assert_consumed()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oHOql35k3Dd"
      },
      "source": [
        "Note: The pretrained `TransformerEncoder` is also available on [TensorFlow Hub](https://tensorflow.org/hub). See the [Hub appendix](#hub_bert) for details. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8qXKRZuCwW4"
      },
      "source": [
        "# Set up the optimizer\n",
        "# BERT adopts the Adam optimizer with weight decay (aka \"[AdamW](https://arxiv.org/abs/1711.05101)\").\n",
        "# It also employs a learning rate schedule that firstly warms up from 0 and then decays to 0.\n",
        "\n",
        "# Set up epochs and steps\n",
        "epochs = 3\n",
        "batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "train_data_size = len(glue_train_labels)\n",
        "steps_per_epoch = int(train_data_size / batch_size)\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "warmup_steps = int(epochs * train_data_size * 0.1 / batch_size)\n",
        "\n",
        "# creates an optimizer with learning rate schedule\n",
        "optimizer = nlp.optimization.create_optimizer(\n",
        "    2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQNA16bhDpky"
      },
      "source": [
        "# This returns an `AdamWeightDecay`  optimizer with the learning rate schedule set:\n",
        "\n",
        "type(optimizer)\n",
        "\n",
        "# To see an example of how to customize the optimizer and it's schedule,\n",
        "# see the [Optimizer schedule appendix](#optiizer_schedule)."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78FEUOOEkoP0"
      },
      "source": [
        "#### <font color = green> **5.6.** </font> Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzi8hjeTQTRs"
      },
      "source": [
        "# The metric is accuracy and we use sparse categorical cross-entropy as loss.\n",
        "\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "bert_classifier.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=loss,\n",
        "    metrics=metrics)\n",
        "\n",
        "bert_classifier.fit(\n",
        "    glue_train, glue_train_labels,\n",
        "    validation_data=(glue_validation, glue_validation_labels),\n",
        "    batch_size=32,\n",
        "    epochs=epochs)\n",
        "\n",
        "# 1エポック1分以内@GPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZoUgDUNJPz3"
      },
      "source": [
        "# Now run the fine-tuned model on a custom example to see that it works.\n",
        "# Start by encoding some sentence pairs:\n",
        "\n",
        "my_examples = bert_encode(\n",
        "    glue_dict = {\n",
        "        'sentence1':['The rain in Spain falls mainly on the plain.',\n",
        "                     'Look I fine tuned BERT.'],\n",
        "        'sentence2':['It mostly rains on the flat lands of Spain.',\n",
        "                     'Is it working? This does not match.']\n",
        "                 },\n",
        "                 tokenizer=tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umo0ttrgRYIM"
      },
      "source": [
        "# The model should report class `1` \"match\" for the first example\n",
        "# and class `0` \"no-match\" for the second:\n",
        "\n",
        "result = bert_classifier(my_examples, training=False)\n",
        "\n",
        "result = tf.argmax(result).numpy()\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utGl0M3aZCE4"
      },
      "source": [
        "np.array(info.features['label'].names)[result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVo_AnT0l26j"
      },
      "source": [
        "#### <font color = green> **5.7.** </font> Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl5x6nElZqkP"
      },
      "source": [
        "# Often the goal of training a model is to _use_ it for something,\n",
        "# so export the model and then restore it to be sure that it works.\n",
        "\n",
        "export_dir='./saved_model'\n",
        "tf.saved_model.save(bert_classifier, export_dir=export_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "y_ACvKPsVUXC"
      },
      "source": [
        "reloaded = tf.saved_model.load(export_dir)\n",
        "reloaded_result = reloaded([my_examples['input_word_ids'],\n",
        "                            my_examples['input_mask'],\n",
        "                            my_examples['input_type_ids']], training=False)\n",
        "\n",
        "original_result = bert_classifier(my_examples, training=False)\n",
        "\n",
        "# The results are (nearly) identical:\n",
        "print(original_result.numpy())\n",
        "print()\n",
        "print(reloaded_result.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh9UntNdn8hC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nsz9JIin8ep"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}