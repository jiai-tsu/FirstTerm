{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_20210309.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4Jl7Gj3Its6z",
        "zHBmesjcuWGW",
        "VDZx-yAGuluB",
        "wwksUjWJ9uoH",
        "me_GnqmJ9uoM",
        "TkIb1p0o9uoO",
        "kgRMovWV9uoP",
        "VS9dPrLg9uoQ",
        "9_SLjZ7j9uoV",
        "esEz_7kr9uoX",
        "UB9Ulshutls5",
        "TNfHIF71ulLu",
        "RTe5P5ioMJwN",
        "RE-thNbBuPIY",
        "rz4g2r97vaW_",
        "5fG61hxHwnPH",
        "fd1NWMxjfsDd",
        "nBQuibYA4n0n",
        "a_b4ou4TYqUN",
        "xluDl5cXYy4y",
        "kmzGPEy64qmA",
        "RdDqGayx67vv",
        "7e7hKcxn6-zd",
        "QFv-FNYUmvpn",
        "6LO_48Owmx_o",
        "SE1H51Ajm0q1",
        "p-uO6ls8m2O5",
        "y54xnJnuYgJ7",
        "wsINyf1VEQLC",
        "xYEGhEOtzn5W",
        "YgkDE7hzo8r5",
        "aeHumfr7zmMa",
        "QfcsSWswSdGV",
        "RqQ1fIsLwkGE"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyOSFQf192Eo"
      },
      "source": [
        "## 36. 自然言語処理（Natural Language Processing : NLP）\n",
        "<font color=green size=5>続き</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jl7Gj3Its6z"
      },
      "source": [
        "### <font color = blue>**5.** </font> アテンションを用いたIMDBのクラス分類"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHBmesjcuWGW"
      },
      "source": [
        "#### <font color = green> **5.1.** </font> keras.layers.Attention()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_5kvkM9rIlE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSIoUErswMRJ"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "    super(TokenAndPositionEmbedding, self).__init__()\n",
        "    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    maxlen = tf.shape(x)[-1]\n",
        "    positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "    positions = self.pos_emb(positions)\n",
        "    x = self.token_emb(x)\n",
        "    return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sSVP9DpJQx1"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x09E1J0VJQvp"
      },
      "source": [
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GxdNarurPct"
      },
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lJ6qYi0JaqJ"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkKQreVnraeY"
      },
      "source": [
        "inputs = layers.Input(shape=(None,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "#####\n",
        "self_attention = layers.Attention()\n",
        "x = self_attention([x,x])\n",
        "#####\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhufguExz-Q"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v8NJ_xyx17E"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsSKZnutsc77"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "# model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2MlEbA33b18"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, \n",
        "    batch_size=32, ###\n",
        "    epochs=7, ###\n",
        "    validation_data=(x_val, y_val)\n",
        "    )\n",
        "\n",
        "### 1エポック40秒弱"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7scCK4_p_nSM"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "792ct_s6KYs3"
      },
      "source": [
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iulacPtuNzp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZx-yAGuluB"
      },
      "source": [
        "#### <font color = green> **5.2.** </font> keras.layers.MultiHeadAttention()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwksUjWJ9uoH"
      },
      "source": [
        "##### Text classification with Transformer\n",
        "\n",
        "**Author:** [Apoorv Nandan](https://twitter.com/NandanApoorv)<br>\n",
        "**Date created:** 2020/05/10<br>\n",
        "**Last modified:** 2020/05/10<br>\n",
        "**Description:** Implement a Transformer block as a Keras layer and use it for text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me_GnqmJ9uoM"
      },
      "source": [
        "##### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5w-z-mA9uoM"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkIb1p0o9uoO"
      },
      "source": [
        "##### Implement a Transformer block as a layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrp6Vtwf9uoO"
      },
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "  def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "    self.ffn = keras.Sequential(\n",
        "        [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "    self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.dropout1 = layers.Dropout(rate)\n",
        "    self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "  def call(self, inputs, training):\n",
        "    attn_output = self.att(inputs, inputs)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(inputs + attn_output)\n",
        "    ffn_output = self.ffn(out1)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    return self.layernorm2(out1 + ffn_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgRMovWV9uoP"
      },
      "source": [
        "##### Implement embedding layer\n",
        "\n",
        "Two seperate embedding layers, one for tokens, one for token index (positions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld-KaK499uoP"
      },
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "    super(TokenAndPositionEmbedding, self).__init__()\n",
        "    self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "    self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "  def call(self, x):\n",
        "    maxlen = tf.shape(x)[-1]\n",
        "    positions = tf.range(start=0, limit=maxlen, delta=1)\n",
        "    positions = self.pos_emb(positions)\n",
        "    x = self.token_emb(x)\n",
        "    return x + positions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS9dPrLg9uoQ"
      },
      "source": [
        "##### Download and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfZjVUTjGa8G"
      },
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "maxlen = 200  # Only consider the first 200 words of each movie review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k7BnKUpGa51"
      },
      "source": [
        "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "print(len(x_train), \"Training sequences\")\n",
        "print(len(x_val), \"Validation sequences\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJlM8vTP9uoV"
      },
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_SLjZ7j9uoV"
      },
      "source": [
        "##### Create classifier model using transformer layer\n",
        "\n",
        "Transformer layer outputs one vector for each time step of our input sequence.\n",
        "Here, we take the mean across all time steps and\n",
        "use a feed forward network on top of it to classify text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BR5dbeNGYHA"
      },
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2s9NzOC9uoW"
      },
      "source": [
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "#####\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "#####\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72nKPBIfFSZW"
      },
      "source": [
        "###\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62L24tLIFABZ"
      },
      "source": [
        "###\n",
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esEz_7kr9uoX"
      },
      "source": [
        "##### Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmc4IlN5GUj7"
      },
      "source": [
        "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4IMwql89uoX"
      },
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=32,  ###\n",
        "    epochs=2, ###\n",
        "    validation_data=(x_val, y_val)\n",
        "    )\n",
        "\n",
        "### 1エポック130〜140秒"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkT0LnkcEHtx"
      },
      "source": [
        "###\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS0aD1DlLQgd"
      },
      "source": [
        "###\n",
        "plt.figure(figsize = (12, 8))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHAZEwKGLTSl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_9LZM_xuOjd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "### <font color = blue>**4.** </font> アテンションを用いたニューラル機械翻訳１（スペイン語→英語）\n",
        "\n",
        "Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmjh290raIky"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiwtNgENbx2g"
      },
      "source": [
        "このノートブックでは、スペイン語から英語への翻訳を行う Sequence to Sequence (seq2seq) モデルを訓練します。\n",
        "\n",
        "このチュートリアルは、 Sequence to Sequence モデルの知識があることを前提にした上級編のサンプルです。\n",
        "\n",
        "このノートブックのモデルを訓練すると、_\"¿todavia estan en casa?\"_  のようなスペイン語の文を入力して、英訳：  _\"are you still at home?\"_  を得ることができます。\n",
        "\n",
        "この翻訳品質はおもちゃとしてはそれなりのものですが、生成されたアテンションの図表の方が面白いかもしれません。\n",
        "\n",
        "これは、翻訳時にモデルが入力文のどの部分に注目しているかを表しています。\n",
        "\n",
        "<img src=\"https://tensorflow.org/images/spanish-english.png\" alt=\"spanish-english attention plot\" width=\"450\" height=\"450\">\n",
        "\n",
        "Note: このサンプルは P100 GPU 1基で実行した場合に約 10 分かかります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfWtimuetezZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB9Ulshutls5"
      },
      "source": [
        "#### <font color = green> **4.1.** </font> データセットのダウンロードと準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa"
      },
      "source": [
        "http://www.manythings.org/anki/ で提供されている言語データセットを使用します。\n",
        "\n",
        "このデータセットには、次のような書式の言語翻訳ペアが含まれています。\n",
        "\n",
        "```\n",
        "May I borrow this book?\t¿Puedo tomar prestado este libro?\n",
        "```\n",
        "\n",
        "さまざまな言語が用意されていますが、ここでは英語ースペイン語のデータセットを使用します。\n",
        "\n",
        "利便性を考えてこのデータセットは Google Cloud 上に用意してありますが、ご自分でダウンロードすることも可能です。\n",
        "\n",
        "データセットをダウンロードしたあと、データを準備するために下記のようないくつかの手順を実行します。\n",
        "\n",
        "1. それぞれの文ごとに、*開始* と *終了* のトークンを付加する\n",
        "2. 特殊文字を除去して文をきれいにする\n",
        "3. 単語インデックスと逆単語インデックス（単語 → id と id → 単語のマッピングを行うディクショナリ）を作成する\n",
        "4. 最大長にあわせて各文をパディングする"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVATYOgJs1b"
      },
      "source": [
        "# ファイルのダウンロード\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file(\n",
        "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "    extract=True)\n",
        "\n",
        "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd0jw-eC3jEh"
      },
      "source": [
        "# ユニコードファイルを ascii に変換\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # 単語とそのあとの句読点の間にスペースを挿入\n",
        "  # 例：　\"he is a boy.\" => \"he is a boy .\"\n",
        "  # 参照：- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # (a-z, A-Z, \".\", \"?\", \"!\", \",\") 以外の全ての文字をスペースに置き換え\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "\n",
        "  w = w.rstrip().strip()\n",
        "\n",
        "  # 文の開始と終了のトークンを付加\n",
        "  # モデルが予測をいつ開始し、いつ終了すれば良いかを知らせるため\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opI2GzOt479E"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHikE_NmuUkJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn4Dct23jEm"
      },
      "source": [
        "# 1. アクセント記号を除去\n",
        "# 2. 文をクリーニング\n",
        "# 3. [ENGLISH, SPANISH] の形で単語のペアを返す\n",
        "\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTbSbBz55QtF"
      },
      "source": [
        "en, sp = create_dataset(path_to_file, None)\n",
        "print(en[-1])\n",
        "print(sp[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmMZQpdO60dt"
      },
      "source": [
        "def max_length(tensor):\n",
        "  return max(len(t) for t in tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIOn8RCNDJXG"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # クリーニングされた入力と出力のペアを生成\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Akzbj_MunKf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnxC7q-j3jFD"
      },
      "source": [
        "## データセットのサイズを制限（オプション）\n",
        "\n",
        "num_examples = 10000  ### 30000 -> 10000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# ターゲットテンソルの最大長を計算\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QILQkOs3jFG"
      },
      "source": [
        "# 80-20で分割を行い、訓練用と検証用のデータセットを作成\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# 長さを表示\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPmLZGMeD5q"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print(\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXukARTDd7MT"
      },
      "source": [
        "print(\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print()\n",
        "print(\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRV1NfPVvFsq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "## tf.data データセットの作成\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 256 ### 64 -> 256\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 64 ### 256 -> 64\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6-NK1GtWQt"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9WIb7fHvO9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNfHIF71ulLu"
      },
      "source": [
        "#### <font color = green> **4.2.** </font> エンコーダー・デコーダーモデルの記述"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vgyIKhvvnsM"
      },
      "source": [
        "下図は、入力の単語ひとつひとつにアテンション機構によって重みが割り当てられ、それを使ってデコーダーが文中の次の単語を予測することを示しています。\n",
        "\n",
        "下記の図と式は [Luong の論文](https://arxiv.org/abs/1508.04025v5) にあるアテンション機構の例です。\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_mechanism.jpg\" width=\"500\" alt=\"attention mechanism\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ6Ly8ju2mg1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbpWvpoSvqIJ"
      },
      "source": [
        "入力がエンコーダーを通過すると、\n",
        "\n",
        "shape が *(batch_size, max_length, hidden_size)* のエンコーダー出力と、\n",
        "\n",
        "shape が *(batch_size, hidden_size)* のエンコーダーの隠れ状態が得られます。\n",
        "\n",
        "下記に実装されている式を示します。\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_0.jpg\" alt=\"attention equation 0\" width=\"800\">\n",
        "<img src=\"https://www.tensorflow.org/images/seq2seq/attention_equation_1.jpg\" alt=\"attention equation 1\" width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W48vogKl2ncv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUcZPLzQvqnN"
      },
      "source": [
        "このチュートリアルでは、エンコーダーでは [Bahdanau attention](https://arxiv.org/pdf/1409.0473.pdf) を使用します。\n",
        "\n",
        "簡略化した式を書く前に、表記方法を定めましょう。\n",
        "\n",
        "* FC = 全結合 (Dense) レイヤー\n",
        "* EO = エンコーダーの出力\n",
        "* H = 隠れ状態\n",
        "* X = デコーダーへの入力"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbhbuO1r2oJ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsV-ApqBvbNZ"
      },
      "source": [
        "擬似コードは下記のとおりです。\n",
        "\n",
        "* `score = FC(tanh(FC(EO) + FC(H)))`\n",
        "* `attention weights = softmax(score, axis = 1)`　softmax は既定では最後の軸に対して実行されますが、スコアの shape が *(batch_size, max_length, hidden_size)*　であるため、*最初の軸* に適用します。`max_length` は入力の長さです。入力それぞれに重みを割り当てようとしているので、softmax はその軸に適用されなければなりません。\n",
        "* `context vector = sum(attention weights * EO, axis = 1)`. 上記と同様の理由で axis = 1 に設定しています。\n",
        "* `embedding output` = デコーダーへの入力 X は Embedding レイヤーを通して渡されます。\n",
        "* `merged vector = concat(embedding output, context vector)`\n",
        "* この結合されたベクトルがつぎに GRU に渡されます。\n",
        "\n",
        "それぞれのステップでのベクトルの shape は、コードのコメントに指定されています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyV5ptODv9Ay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gSVh05Jl6l"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# サンプル入力\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umohpBN2OM94"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, query, values):\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # スコアを計算するためにこのように加算を実行する\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # スコアを self.V に適用するために最後の軸は 1 となる\n",
        "    # self.V に適用する前のテンソルの shape は  (batch_size, max_length, units)\n",
        "    score = self.V(tf.nn.tanh(\n",
        "        self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights の shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # context_vector の合計後の shape == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k534zTHiDjQU"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ_B3mhW3jFk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    # アテンションのため\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output の shape == (batch_size, max_length, hidden_size)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # 埋め込み層を通過したあとの x の shape  == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # 結合後の x の shape == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # 結合したベクトルを GRU 層に渡す\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UY8wko3jFp"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((256,  ### 64 -> 256\n",
        "                                                         1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diuu40tlwJhq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "source": [
        "## オプティマイザと損失関数の定義\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVwtZVQmwfip"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bXQTgNwrF"
      },
      "source": [
        "## チェックポイント（オブジェクトベースの保存）\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUnOUOj_wggw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpObfY22IddU"
      },
      "source": [
        "#### <font color = green> **4.3.** </font> 学習の実行"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MbAonKcwtDl"
      },
      "source": [
        "1. *入力* を *エンコーダー* に通すと、*エンコーダー出力* と *エンコーダーの隠れ状態* が返される\n",
        "2. エンコーダーの出力とエンコーダーの隠れ状態、そしてデコーダーの入力（これが *開始トークン*）がデコーダーに渡される\n",
        "3. デコーダーは *予測値* と *デコーダーの隠れ状態* を返す\n",
        "4. つぎにデコーダーの隠れ状態がモデルに戻され、予測値が損失関数の計算に使用される\n",
        "5. デコーダーへの次の入力を決定するために *Teacher Forcing* が使用される\n",
        "6. *Teacher Forcing* は、*正解単語* をデコーダーの *次の入力* として使用するテクニックである\n",
        "7. 最後に勾配を計算し、それをオプティマイザに与えて誤差逆伝播を行う"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9ArXSsVfqn"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher Forcing - 正解値を次の入力として供給\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # passing enc_output to the decoder\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "      # Teacher Forcing を使用\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "  return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0"
      },
      "source": [
        "EPOCHS = 1 ### 10 -> 1\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
        "  # 2 エポックごとにモデル（のチェックポイント）を保存\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
        "\n",
        "  ## 1エポック190〜200秒かかる"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "#### <font color = green> **4.4.** </font> 翻訳"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S38bTJIPxY_X"
      },
      "source": [
        "* 評価関数は、*Teacher Forcing* を使わないことを除いては、訓練ループと同様である。タイムステップごとのデコーダーへの入力は、過去の予測値に加えて、隠れ状態とエンコーダーのアウトプットである。\n",
        "* モデルが *終了トークン* を予測したら、予測を停止する。\n",
        "* また、*タイムステップごとのアテンションの重み*　を保存する。\n",
        "\n",
        "Note: エンコーダーの出力は 1 つの入力に対して 1 回だけ計算されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "    # 後ほどプロットするためにアテンションの重みを保存\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # 予測された ID がモデルに戻される\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5hQWlbN3jGF"
      },
      "source": [
        "# アテンションの重みをプロットする関数\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9zUHzg3jGI"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))\n",
        "\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTHDUTunzn_8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpT9D5_OgP6"
      },
      "source": [
        "## checkpoint_dir の中の最後のチェックポイントを復元しテストする\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrAM0FDomq3E"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx2iM36EZQZ"
      },
      "source": [
        "translate(u'esta es mi vida.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LLCx3ZE0Ls"
      },
      "source": [
        "translate(u'¿todavia estan en casa?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW"
      },
      "source": [
        "# 翻訳あやまりの例\n",
        "translate(u'trata de averiguarlo.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTe5P5ioMJwN"
      },
      "source": [
        "#### <font color = green> **4.5.** </font> 次のステップ\n",
        "\n",
        "* [異なるデータセットをダウンロード](http://www.manythings.org/anki/)して翻訳の実験を行ってみよう。たとえば英語からドイツ語や、英語からフランス語。\n",
        "* もっと大きなデータセットで訓練を行ったり、もっと多くのエポックで訓練を行ったりしてみよう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhMHYHPcz4YK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE-thNbBuPIY"
      },
      "source": [
        "### <font color = blue>**6.** </font> アテンションを用いたニューラル機械翻訳２（英語→日本語）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0E-O0RblLUN"
      },
      "source": [
        "import urllib.request\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B4vsjcOXQ8d"
      },
      "source": [
        "original_sentences_ja = urllib.request.urlopen(\n",
        "    'https://raw.githubusercontent.com/jiai-tus/FirstTerm/main/20210309/datasets/train_ja.txt'\n",
        "    ).read().decode('utf-8').strip().split('\\n')[:]\n",
        "\n",
        "#len(original_sentences_ja)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8P9kp09ZfeC"
      },
      "source": [
        "original_sentences_en = urllib.request.urlopen(\n",
        "    'https://raw.githubusercontent.com/jiai-tus/FirstTerm/main/20210309/datasets/train_en.txt'\n",
        "    ).read().decode('utf-8').strip().split('\\n')[:]\n",
        "\n",
        "#len(original_sentences_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBN5GkSoo0V2"
      },
      "source": [
        "def prepare(data):\n",
        "  for i  in  range(len(data)):\n",
        "    data[i] = '<s> ' + data[i] + ' </s>'\n",
        "  return [ data[i].split(' ') for i in range(len(data))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx0nQUu8lLN3"
      },
      "source": [
        "def prepare(data):\n",
        "  for i  in  range(len(data)):\n",
        "    data[i] = '<s> ' + data[i] + ' </s>'\n",
        "  return [ data[i].split(' ') for i in range(len(data))]\n",
        "\n",
        "num_samples = len(original_sentences_en)  ### 50000\n",
        "\n",
        "sentences_ja = prepare(original_sentences_ja, num_samples)\n",
        "sentences_en = prepare(original_sentences_en, num_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oNXNysUlLIA"
      },
      "source": [
        "def words(sentences):\n",
        "  return sorted(list(set([e for i in sentences for e in i])))\n",
        "\n",
        "words_ja = words(sentences_ja)\n",
        "words_en = words(sentences_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pddTe6N6mc4h"
      },
      "source": [
        "def numerate(sentences,words_list):\n",
        "  numbers = [[words_list.index(sentences[i][k])+1 for k in range(len(sentences[i]))] for i in range(len(sentences))]\n",
        "  return pad_sequences(numbers, padding='post')\n",
        "\n",
        "sentences_ja = numerate(sentences_ja,words_ja)\n",
        "sentences_en = numerate(sentences_en,words_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frRi1jo0AjTu"
      },
      "source": [
        "len_sentences_ja = len(sentences_ja[0])\n",
        "len_sentences_en = len(sentences_en[0])\n",
        "len_words_ja = len(words_ja)+1\n",
        "len_words_en = len(words_en)+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOk4Tc4kAqj5"
      },
      "source": [
        "X_train = [sentences_en, sentences_ja]\n",
        "Y_train = [np.append(sentences_ja[i,1:],[0]) for i in range(num_samples)]\n",
        "Y_train = np.array(Y_train).reshape(num_samples,18,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qG2I0AFdVcz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlKNON9tdVZ-"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Input, Model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Layer, Dropout, LayerNormalization, Dense, Embedding, Lambda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiF79tcgc0qL"
      },
      "source": [
        "def create_padding_mask(x):\n",
        "  \"\"\"\n",
        "  masking as follows,\n",
        "  0 to 1.,\n",
        "  others goes to 0.\n",
        "  1がmaskされる\n",
        "  \"\"\"\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwQxc8mRc0td"
      },
      "source": [
        "def create_look_ahead_mask(x):\n",
        "  \"\"\"\n",
        "  mask the future tokens in a sequence\n",
        "  1がmaskされる\n",
        "  \"\"\"\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C0RdIh7c0we"
      },
      "source": [
        "def scaled_dot_product_attention(query, key, value, mask=None):\n",
        "  \"\"\"\n",
        "  formation:\n",
        "  sdp-attention := attention_weight * value,\n",
        "  ここで, attention_weight := softmax(mask(normalize(query * key_T)))\n",
        "  注意: maskはoptional\n",
        "    \n",
        "  input:\n",
        "  query=shape(batch, head, ?, emb_in_head), float32\n",
        "  key=shape(batch, head, ?, emb_in_head), float32\n",
        "  value=shape(batch, head, ?, emb_in_head), float32\n",
        "  mask=shape(batch, head, ?, emb_in_head), boolean\n",
        "\n",
        "  output:\n",
        "  scaled dot product attention: shape(batch, head, ?, emb_in_head)\n",
        "  \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "  nor_k_size = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(nor_k_size)\n",
        "\n",
        "  if mask is not None:\n",
        "    # if the elements in mask equals zero,  then goes to zero after appling softmax.\n",
        "    # for that reason, the small value close to negative infinity is assigned to non-masked logits\n",
        "    logits += mask * -1e9\n",
        "\n",
        "  attention_weight = tf.nn.softmax(logits, axis=-1)\n",
        "  return tf.matmul(attention_weight, value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvBak2upc0zV"
      },
      "source": [
        "class MultiHeadAttention(Layer):\n",
        "  def __init__(self, emb_dim=256, head=16):\n",
        "    super().__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.head = head\n",
        "    assert emb_dim % head == 0\n",
        "    self.depth = emb_dim // head\n",
        "    self.q_dense = Dense(units=emb_dim)\n",
        "    self.k_dense = Dense(units=emb_dim)\n",
        "    self.v_dense = Dense(units=emb_dim)\n",
        "    self.last_dense = Dense(emb_dim)\n",
        "        \n",
        "  def _split_head(self, inputs, batch_size):\n",
        "    \"\"\"\n",
        "    split input to suit each head attention\n",
        "    input: \n",
        "    inputs=shape(batch, emb, ?)\n",
        "        \n",
        "    output:\n",
        "    outputs=shape(batch, head_number, ?, emb_in_each_head)\n",
        "    scaled dot-product attentionは最後の次元のみ計算に使うので、headの次元を前に持ってくると効率的にmulti-head attentionを求められる\n",
        "    \"\"\"\n",
        "    inp = tf.reshape(inputs, shape=(batch_size, -1, self.head, self.depth))\n",
        "    return tf.transpose(inp, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    q, k, v, mask = inputs['query'], inputs['key'], inputs['value'], inputs['mask']\n",
        "    batch_size = tf.shape(q)[0]\n",
        "        \n",
        "    # split heads\n",
        "    q = self.q_dense(q)\n",
        "    q = self._split_head(q, batch_size)    \n",
        "    k = self.k_dense(k)\n",
        "    k = self._split_head(k, batch_size)\n",
        "    v = self.v_dense(v)\n",
        "    v = self._split_head(v, batch_size)\n",
        "\n",
        "    attention = scaled_dot_product_attention(q, k, v, mask)\n",
        "        \n",
        "    # concat heads\n",
        "    attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
        "    attention = tf.reshape(attention, (batch_size, -1, self.emb_dim))\n",
        "        \n",
        "    outputs = self.last_dense(attention)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viih_kxcc02V"
      },
      "source": [
        "class PositionalEncoding(Layer):\n",
        "  def __init__(self, position, emb_dim):\n",
        "    super().__init__()\n",
        "    self.pos_encoding = self._positional_encoding(position, emb_dim)\n",
        "        \n",
        "  def _get_angles(self, position, i, emb_dim):\n",
        "    \"\"\"\n",
        "    assign position, i and emb_dim to the expression of the angle of positional encoding formulae\n",
        "    outputs: shape=(position.shape[0], i.shape[1])\n",
        "    \"\"\"\n",
        "    denominator = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(emb_dim, tf.float32))\n",
        "    return position * denominator\n",
        "\n",
        "  def _positional_encoding(self, sentence_length, emb_dim):\n",
        "    \"\"\"\n",
        "    inputs:\n",
        "    sentence_length: int\n",
        "    emb_dim: int\n",
        "        \n",
        "    outputs:\n",
        "    output: shape=(1, sentence_length, emb_dim), float32\n",
        "    \"\"\"\n",
        "    # 計算を効率化するためにpositionとiを行列にしてangle計算を行列の積で一度に実行する\n",
        "    angle = self._get_angles(\n",
        "        position=tf.expand_dims(tf.range(sentence_length, dtype=tf.float32), -1),\n",
        "        i=tf.expand_dims(tf.range(emb_dim, dtype=tf.float32), 0),\n",
        "        emb_dim=emb_dim\n",
        "        )\n",
        "        \n",
        "    # インデックスが偶数のものはサイン関数に適応\n",
        "    sine = tf.math.sin(angle[:, 0::2])\n",
        "    # インデックスが奇数のものはコサイン関数に適応\n",
        "    cos = tf.math.cos(angle[:, 1::2])\n",
        "        \n",
        "    pos_encoding = tf.concat([sine, cos], axis=-1)\n",
        "    pos_encoding = tf.expand_dims(pos_encoding, 0)\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    \"\"\"\n",
        "    inputs: shape=(batch, sentence_length, emb_dim)\n",
        "    \"\"\"\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJLcNH_Tc05F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Whv1-Vc1c08X"
      },
      "source": [
        "def encoder_layer(units, emb_dim=256, head=16, dropout=0.2):\n",
        "  inputs = Input(shape=(None, emb_dim))\n",
        "  padding_mask = Input(shape=(1, 1, None))\n",
        "    \n",
        "  # self multi head attention and dropout\n",
        "  self_attention = MultiHeadAttention(emb_dim=emb_dim, head=head)(\n",
        "        {\n",
        "            'query': inputs,\n",
        "            'key': inputs,\n",
        "            'value': inputs,\n",
        "            'mask': padding_mask\n",
        "        }\n",
        "    )\n",
        "  self_attention = Dropout(rate=dropout)(self_attention)\n",
        "    \n",
        "  # Add & Norm\n",
        "  attention = LayerNormalization(epsilon=1e-6)(inputs + self_attention)\n",
        "    \n",
        "  # feed forward\n",
        "  ff = Dense(units=units, activation='relu')(attention)\n",
        "  ff = Dense(units=emb_dim)(ff)\n",
        "  ff = Dropout(rate=dropout)(ff)\n",
        "    \n",
        "  # Add & Norm\n",
        "  outputs = LayerNormalization(epsilon=1e-6)(attention + ff)\n",
        "    \n",
        "  return Model(inputs=[inputs, padding_mask], outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BZ2eENmdShC"
      },
      "source": [
        "def encoder(vocab_size, num_layers, units, emb_dim=256, head=16, dropout=0.2):\n",
        "  \"\"\"\n",
        "  emb -> positional_encoding -> some encoder_layer\n",
        "  \"\"\"\n",
        "  inputs = Input(shape=(None, ))\n",
        "  padding_mask = Input(shape=(1, 1, None))\n",
        "    \n",
        "  emb = Embedding(vocab_size, emb_dim)(inputs)\n",
        "  emb *= tf.math.sqrt(tf.cast(emb_dim, tf.float32))\n",
        "  emb = PositionalEncoding(vocab_size, emb_dim)(emb)\n",
        "    \n",
        "  outputs = Dropout(rate=dropout)(emb)\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        emb_dim=emb_dim,\n",
        "        head=head,\n",
        "        dropout=dropout)([outputs, padding_mask])\n",
        "        \n",
        "  return Model(inputs=[inputs, padding_mask], outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lempt2hidSju"
      },
      "source": [
        "def decoder_layer(units, emb_dim=256, head=16, dropout=0.2):\n",
        "  inputs = Input(shape=(None, emb_dim))\n",
        "  encoder_outputs = Input(shape=(None, emb_dim))\n",
        "  padding_mask = Input(shape=(1, 1, None))\n",
        "  look_ahead_mask = Input(shape=(1, None, None))\n",
        "      \n",
        "  # self multi head attention and dropout\n",
        "  self_attention = MultiHeadAttention(emb_dim=emb_dim, head=head)(\n",
        "      {\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "       })\n",
        "    \n",
        "  # Add & Norm\n",
        "  attention1 = LayerNormalization(epsilon=1e-6)(inputs + self_attention)\n",
        "\n",
        "  attention2 = MultiHeadAttention(emb_dim=emb_dim, head=head)(\n",
        "      {\n",
        "          'query': attention1,\n",
        "          'key': encoder_outputs,\n",
        "          'value': encoder_outputs,\n",
        "          'mask': padding_mask\n",
        "       })\n",
        "  attention2 = Dropout(rate=dropout)(attention2)\n",
        "    \n",
        "  # Add & Norm\n",
        "  attention = LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
        "    \n",
        "  # feed forward\n",
        "  ff = Dense(units=units, activation='relu')(attention)\n",
        "  ff = Dense(units=emb_dim)(ff)\n",
        "  ff = Dropout(rate=dropout)(ff)\n",
        "    \n",
        "  # Add & Norm\n",
        "  outputs = LayerNormalization(epsilon=1e-6)(attention + ff)\n",
        "    \n",
        "  return Model(inputs=[inputs,\n",
        "                       encoder_outputs,\n",
        "                       look_ahead_mask,\n",
        "                       padding_mask],\n",
        "              outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khXbI1oLdSmm"
      },
      "source": [
        "def decoder(vocab_size, num_layers, units, emb_dim=256, head=16, dropout=0.2):\n",
        "  \"\"\"\n",
        "  emb -> positional_encoding -> some decoder_layer\n",
        "  \"\"\"\n",
        "  inputs = Input(shape=(None, ), name=\"inputs\")\n",
        "  encoder_outputs = Input(shape=(None, emb_dim))\n",
        "  padding_mask = Input(shape=(1, 1, None))\n",
        "  look_ahead_mask = Input(shape=(1, None, None))\n",
        "      \n",
        "  emb = Embedding(vocab_size, emb_dim)(inputs)\n",
        "  emb *= tf.math.sqrt(tf.cast(emb_dim, tf.float32))\n",
        "  emb = PositionalEncoding(vocab_size, emb_dim)(emb)\n",
        "    \n",
        "  outputs = Dropout(rate=dropout)(emb)\n",
        "    \n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        emb_dim=emb_dim,\n",
        "        head=head,\n",
        "        dropout=dropout\n",
        "        )([outputs, \n",
        "           encoder_outputs,\n",
        "           look_ahead_mask, \n",
        "           padding_mask])\n",
        "        \n",
        "  return Model(inputs=[inputs,\n",
        "                       encoder_outputs,\n",
        "                       look_ahead_mask,\n",
        "                       padding_mask], \n",
        "               outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OaBc185dgJK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dw1zNZWdgTT"
      },
      "source": [
        "def transformer(vocab_size, num_layers, units, emb_dim=256, head=16, dropout=0.2):\n",
        "  inputs = Input(shape=(None, ))\n",
        "  decoder_inputs = Input(shape=(None, ))\n",
        "    \n",
        "  encoder_padding_mask = Lambda(create_padding_mask, \n",
        "                                output_shape=(1, 1, None))(inputs)  ###\n",
        "  decoder_padding_mask = Lambda(create_padding_mask, \n",
        "                                output_shape=(1, 1, None))(decoder_inputs)  ###\n",
        "  look_ahead_mask = Lambda(create_look_ahead_mask, \n",
        "                           output_shape=(1, None, None))(decoder_inputs)\n",
        "    \n",
        "  encoder_outputs = encoder(vocab_size=vocab_size,\n",
        "                            num_layers=num_layers,\n",
        "                            units=units,\n",
        "                            emb_dim=emb_dim,\n",
        "                            head=head,\n",
        "                            dropout=dropout\n",
        "                            )(inputs=[inputs, encoder_padding_mask])\n",
        "\n",
        "  decoder_outputs = decoder(vocab_size=vocab_size,\n",
        "                            num_layers=num_layers,\n",
        "                            units=units,\n",
        "                            emb_dim=emb_dim,\n",
        "                            head=head,\n",
        "                            dropout=dropout\n",
        "                            )(inputs=[decoder_inputs, \n",
        "                                      encoder_outputs, \n",
        "                                      look_ahead_mask, \n",
        "                                      decoder_padding_mask])\n",
        "\n",
        "  outputs = Dense(units=vocab_size, activation='softmax')(decoder_outputs)\n",
        "\n",
        "  return Model(inputs=[inputs, decoder_inputs], outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLpC4sT9dgWW"
      },
      "source": [
        "NUM_LAYERS = 2\n",
        "EMB_DIM = 256\n",
        "NUM_HEADS = 16\n",
        "UNITS = 512\n",
        "DROPOUT = 0.2\n",
        "VOCAB_SIZE = len_words_ja\n",
        "\n",
        "sample_transformer = transformer(vocab_size=VOCAB_SIZE,\n",
        "                                 num_layers=NUM_LAYERS,\n",
        "                                 units=UNITS,\n",
        "                                 emb_dim=EMB_DIM,\n",
        "                                 head=NUM_HEADS,\n",
        "                                 dropout=DROPOUT)\n",
        "\n",
        "tf.keras.utils.plot_model(sample_transformer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5G-UKYdhVCH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umiE1Y3QeFkA"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "NUM_LAYERS = 2\n",
        "EMB_DIM = 256\n",
        "NUM_HEADS = 2\n",
        "UNITS = 16\n",
        "DROPOUT = 0.2\n",
        "\n",
        "model = transformer(vocab_size=VOCAB_SIZE,\n",
        "                    num_layers=NUM_LAYERS,\n",
        "                    units=UNITS,\n",
        "                    emb_dim=EMB_DIM,\n",
        "                    head=NUM_HEADS,\n",
        "                    dropout=DROPOUT)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0Li0ReyeFmv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50UpoYYOfh-X"
      },
      "source": [
        "history = model.fit(X_train, Y_train, \n",
        "                    batch_size=128, \n",
        "                    epochs=5, \n",
        "                    verbose=1, \n",
        "                    validation_split=0.2)\n",
        "\n",
        "### 1エポック450秒くらい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zqIp0W967lN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43QRnJGo6710"
      },
      "source": [
        "bos = words_ja.index('<s>') +1  \n",
        "eos = words_ja.index('</s>') +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DLq5ysYi4KK"
      },
      "source": [
        "def encode_decode(input_seq):\n",
        "  proposed_word = bos\n",
        "  output_seq = np.array([0 for k in range(len_sentences_ja)])\n",
        "\n",
        "  for i in range(1,len_sentences_ja):\n",
        "    output_seq[i] = proposed_word\n",
        "    predictions = model.predict([input_seq, output_seq])\n",
        "    proposed_word = np.argmax(predictions[i, 0, :]) \n",
        "\n",
        "    if proposed_word == eos:\n",
        "      output_seq[i] = proposed_word\n",
        "      break\n",
        "\n",
        "  return output_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNy3MESjfiGq"
      },
      "source": [
        "def recover(sentence,words_list):\n",
        "  answer_seq = []\n",
        "\n",
        "  for i in range(len(sentence)):\n",
        "    if sentence[i] > 0:\n",
        "      answer_seq += words_list[sentence[i]-1]\n",
        "      \n",
        "  return \"\".join(answer_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bf3Yj1cfiJK"
      },
      "source": [
        "def translate(input_sentences):\n",
        "  input_sentences = prepare(input_sentences)\n",
        "  input_sentences = numerate(input_sentences, words_en)\n",
        "  input_sentences = np.array([ list(input_sentences[k]) \n",
        "          + [0 for i in range(len_sentences_en-len(input_sentences[k]))] for k in range(len(input_sentences))])\n",
        "  output_sentences = [ encode_decode(input_sentences[i]) for i in range(len(input_sentences))]\n",
        "\n",
        "  return [recover(output_sentences[i],words_ja) for i in range(len(input_sentences))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RS1HCxnfiMd"
      },
      "source": [
        "translate(['she likes you .'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdCvWgjQfiU8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO0HAFeZuOa6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz4g2r97vaW_"
      },
      "source": [
        "### <font color = blue>**7.** </font> アテンションを用いたニューラル機械翻訳３（ポルトガル語→英語）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_qNSzzyaCbD"
      },
      "source": [
        "Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fBeO5sVwnPG"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fG61hxHwnPH"
      },
      "source": [
        "##### 言語理解のためのTransformerモデル"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tudzcncJXetB"
      },
      "source": [
        "Note: これらのドキュメントは私たちTensorFlowコミュニティが翻訳したものです。コミュニティによる 翻訳は**ベストエフォート**であるため、この翻訳が正確であることや[英語の公式ドキュメント](https://www.tensorflow.org/?hl=en)の 最新の状態を反映したものであることを保証することはできません。 この翻訳の品質を向上させるためのご意見をお持ちの方は、GitHubリポジトリ[tensorflow/docs](https://github.com/tensorflow/docs)にプルリクエストをお送りください。 コミュニティによる翻訳やレビューに参加していただける方は、 [docs-ja@tensorflow.org メーリングリスト](https://groups.google.com/a/tensorflow.org/forum/#!forum/docs-ja)にご連絡ください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce5v4eQr3suy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRE4ESY23yrx"
      },
      "source": [
        "このチュートリアルでは、ポルトガル語を英語に翻訳する<a href=\"https://arxiv.org/abs/1706.03762\" class=\"external\">Transformerモデル</a>を訓練します。これは上級編のサンプルで、[テキスト生成](text_generation.ipynb)や[アテンション（注意機構）](nmt_with_attention.ipynb)の知識を前提としています。\n",
        "\n",
        "Transformerモデルの背後にある中心的なアイデアは*セルフアテンション（自己注意）*、 つまり、シーケンスの表現を計算するために入力シーケンスの異なる位置に注意を払うことができることにあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC-Ommep30fa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZGKwhlI33YG"
      },
      "source": [
        "Transformerモデルは、[RNNs](text_classification_rnn.ipynb)や[CNNs](../images/intro_to_cnns.ipynb)の代わりに セルフアテンション・レイヤーを重ねたものを使って、可変長の入力を扱います。この一般的なアーキテクチャにはいくつもの利点があります。\n",
        "\n",
        "* データの中の時間的／空間的な関係を前提にしません。これは、オブジェクトの集合（例えば、[StarCraftのユニット](https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/#block-8))を扱うには理想的です。\n",
        "* レイヤーの出力はRNNのような系列ではなく、並列に計算可能です。\n",
        "* たくさんのRNNのステップや畳み込み層を経ることなく、離れた要素どうしが互いの出力に影響を与えることができます（例えば、[Scene Memory Transformer](https://arxiv.org/pdf/1903.03878.pdf)を参照)。\n",
        "* 長距離の依存関係を学習可能です。これは、シーケンスを扱うタスクにおいては難しいことです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWnZ857Z34sp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-f8TnGpE_ex"
      },
      "source": [
        "このアーキテクチャの欠点は次のようなものです。\n",
        "\n",
        "* 時系列では、あるタイムステップの出力が、入力とその時の隠れ状態だけからではなく、*過去全て*から計算されます。\n",
        "* テキストのように、入力に時間的／空間的な関係が*存在する*場合、何らかの位置エンコーディングを追加しなければなりません。さもなければ、モデルは実質的にバッグ・オブ・ワード（訳注：Bag of Word、含まれる単語の集合）を見ることになります。\n",
        "\n",
        "このノートブックのモデルを訓練したあとには、ポルトガル語の文を入力し、英語の翻訳を得ることができます。\n",
        "\n",
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/attention_map_portuguese.png\" width=\"800\" alt=\"Attention heatmap\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjJJyJTZYebt"
      },
      "source": [
        "!pip install tf-nightly\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1NWMxjfsDd"
      },
      "source": [
        "##### 入力パイプラインの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4_Qt8W1hJE_"
      },
      "source": [
        "[TFDS](https://www.tensorflow.org/datasets)を使って、[TED Talks Open Translation Project](https://www.ted.com/participate/translate)から[Portugese-English translation dataset](https://github.com/neulab/word-embeddings-for-nmt)をロードします。\n",
        "\n",
        "このデータセットには、約50000の訓練用サンプルと、1100の検証用サンプル、2000のテスト用サンプルが含まれています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q9t4FmN96eN"
      },
      "source": [
        "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
        "                               as_supervised=True)\n",
        "train_examples, val_examples = examples['train'], examples['validation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k57IEihL1Kjw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwwqPz2I1KfK"
      },
      "source": [
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77qFS_hUpyCt"
      },
      "source": [
        "examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMYyZ7otp26x"
      },
      "source": [
        "len(examples['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZT6Sznlp23V"
      },
      "source": [
        "type(examples['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mAds39Qp20D"
      },
      "source": [
        "examples['train'].as_numpy_iterator().next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZjyG5AtsuPI"
      },
      "source": [
        "train_examples.as_numpy_iterator().next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of5qjkGZsuLY"
      },
      "source": [
        "len(train_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmOpghMKsuGJ"
      },
      "source": [
        "val_examples.as_numpy_iterator().next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygFVHLoup2wf"
      },
      "source": [
        "len(val_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THnYDagxpx7b"
      },
      "source": [
        "###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmSaaGgo1LoI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCEKotqosGfq"
      },
      "source": [
        "訓練用データセットから、カスタムのサブワード・トークナイザーを作成します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVBg5Q8tBk5z"
      },
      "source": [
        "# tfds.features.text.~ -> tfds.deprecated.text.~ (非推奨)\n",
        "tokenizer_en = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (en.numpy() for pt, en in train_examples), target_vocab_size=2**13)\n",
        "\n",
        "tokenizer_pt = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    (pt.numpy() for pt, en in train_examples), target_vocab_size=2**13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DYWukNFkGQN"
      },
      "source": [
        "sample_string = 'Transformer is awesome.'\n",
        "\n",
        "tokenized_string = tokenizer_en.encode(sample_string)\n",
        "print ('Tokenized string is {}'.format(tokenized_string))\n",
        "\n",
        "original_string = tokenizer_en.decode(tokenized_string)\n",
        "print ('The original string: {}'.format(original_string))\n",
        "\n",
        "assert original_string == sample_string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9KJWJjrsZ4Y"
      },
      "source": [
        "このトークナイザーは、単語が辞書にない場合には文字列をサブワードに分解してエンコードします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf2ntBxjkqK6"
      },
      "source": [
        "for ts in tokenized_string:\n",
        "  print ('{} ----> {}'.format(ts, tokenizer_en.decode([ts])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcRp7VcQ5m6g"
      },
      "source": [
        "BUFFER_SIZE = 20000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGi4PoVakxdc"
      },
      "source": [
        "入力とターゲットに開始及び終了トークンを追加します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZwnPr4R055s"
      },
      "source": [
        "def encode(lang1, lang2):\n",
        "  lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(\n",
        "      lang1.numpy()) + [tokenizer_pt.vocab_size+1]\n",
        "\n",
        "  lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(\n",
        "      lang2.numpy()) + [tokenizer_en.vocab_size+1]\n",
        "  \n",
        "  return lang1, lang2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx1sFbR-9fRs"
      },
      "source": [
        "データセットの各要素にこの関数を適用するために、`Dataset.map`を使いたいと思います。`Dataset.map`はグラフモードで動作します。\n",
        "\n",
        "* グラフテンソルは値を持ちません。\n",
        "* グラフモードでは、TensorFlowの演算と関数しか使えません。\n",
        "\n",
        "このため、この関数を直接`.map`することはできません。`tf.py_function`でラップする必要があります。`tf.py_function`は（値とそれにアクセスするための`.numpy()`メソッドを持つ）通常のテンソルを、ラップされたPython関数に渡します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mah1cS-P70Iz"
      },
      "source": [
        "def tf_encode(pt, en):\n",
        "  result_pt, result_en = tf.py_function(encode, [pt, en], [tf.int64, tf.int64])\n",
        "  result_pt.set_shape([None])\n",
        "  result_en.set_shape([None])\n",
        "\n",
        "  return result_pt, result_en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JrGp5Gek6Ql"
      },
      "source": [
        "Note: このサンプルを小さく、より速くするため、長さが40トークンを超えるサンプルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QEgbjntk6Yf"
      },
      "source": [
        "MAX_LENGTH = 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c081xPGv1CPI"
      },
      "source": [
        "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
        "  return tf.logical_and(tf.size(x) <= max_length,\n",
        "                        tf.size(y) <= max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fw2YSL3SXE1"
      },
      "source": [
        "train_preprocessed = (\n",
        "    train_examples\n",
        "    .map(tf_encode) \n",
        "    .filter(filter_max_length)\n",
        "    # 読み取り時のスピードアップのため、データセットをメモリ上にキャッシュする\n",
        "    .cache()\n",
        "    .shuffle(BUFFER_SIZE))\n",
        "\n",
        "val_preprocessed = (\n",
        "    val_examples\n",
        "    .map(tf_encode)\n",
        "    .filter(filter_max_length))        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9CP7sLlFMpb"
      },
      "source": [
        "パディングとバッチ化の両方を行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mk9AZdZ5bcS"
      },
      "source": [
        "train_dataset = (train_preprocessed\n",
        "                 .padded_batch(BATCH_SIZE, padded_shapes=([None], [None]))\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "\n",
        "val_dataset = (val_preprocessed\n",
        "               .padded_batch(BATCH_SIZE,  padded_shapes=([None], [None])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIbblR_Ri-FI"
      },
      "source": [
        "Note: **TensorFlow 2.2** から、padded_shapes は必須ではなくなりました。デフォルトではすべての軸をバッチ中で最も長いものに合わせてパディングします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5rsX9zLlK8t"
      },
      "source": [
        "train_dataset = (train_preprocessed\n",
        "                 .padded_batch(BATCH_SIZE)\n",
        "                 .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "\n",
        "val_dataset = (val_preprocessed\n",
        "               .padded_batch(BATCH_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AizWyxQ64wB0"
      },
      "source": [
        "後でコードをテストするために、検証用データセットからバッチを一つ取得しておきます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fXvfYVfQr2n"
      },
      "source": [
        "pt_batch, en_batch = next(iter(val_dataset))\n",
        "pt_batch, en_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBQuibYA4n0n"
      },
      "source": [
        "##### 位置エンコーディング\n",
        "\n",
        "このモデルには再帰や畳込みが含まれないので、モデルに文中の単語の相対的な位置の情報を与えるため、位置エンコーディングを追加します。\n",
        "\n",
        "位置エンコーディングベクトルは埋め込みベクトルに加算します。埋め込みはトークンをd次元空間で表現します。そこでは、同じような意味を持つトークンが近くに位置することになります。しかし、埋め込みは単語の文中の相対的位置をエンコードしません。したがって、位置エンコーディングを加えることで、単語は、d次元空間の中で、*意味と文中の位置の近さ*にもとづいて近くに位置づけられます。\n",
        "\n",
        "もう少し知りたければ [位置エンコーディング](https://github.com/tensorflow/examples/blob/master/community/en/position_encoding.ipynb) のノートブックを参照してください。位置エンコーディングを計算する式は下記のとおりです。\n",
        "\n",
        "$$\\Large{PE_{(pos, 2i)} = sin(pos / 10000^{2i / d_{model}})} $$\n",
        "$$\\Large{PE_{(pos, 2i+1)} = cos(pos / 10000^{2i / d_{model}})} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhIOZjMNKujn"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "  return pos * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rz82wEs5biZ"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                          np.arange(d_model)[np.newaxis, :],\n",
        "                          d_model)\n",
        "  \n",
        "  # 配列中の偶数インデックスにはsinを適用; 2i\n",
        "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "  \n",
        "  # 配列中の奇数インデックスにはcosを適用; 2i+1\n",
        "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    \n",
        "  pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    \n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kLCla68EloE"
      },
      "source": [
        "pos_encoding = positional_encoding(50, 512)\n",
        "print (pos_encoding.shape)\n",
        "\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.xlim((0, 512))\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_b4ou4TYqUN"
      },
      "source": [
        "##### マスキング"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s42Uydjkv0hF"
      },
      "source": [
        "シーケンスのバッチ中のパディングされた全てのトークンをマスクします。これにより、モデルがパディングを確実に入力として扱わないようにします。マスクは、パディング値`0`の存在を示します。つまり、`0`の場所で`1`を出力し、それ以外の場所では`0`を出力します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2i8-e1s8ti9"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # アテンション・ロジットにパディングを追加するため\n",
        "  # さらに次元を追加する\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7BYeBCNvi7n"
      },
      "source": [
        "x = tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]])\n",
        "create_padding_mask(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0hzukDBgVom"
      },
      "source": [
        "シーケンス中の未来のトークンをマスクするため、 ルックアヘッド・マスクが使われています。言い換えると、このマスクはどのエントリーを使うべきではないかを示しています。\n",
        "\n",
        "これは、3番めの単語を予測するために、1つ目と2つ目の単語だけが使われるということを意味しています。同じように4つ目の単語を予測するには、1つ目、2つ目と3つ目の単語だけが使用され、次も同様となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVxS8OPI9uI0"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "  mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "  return mask  # (seq_len, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxKGuXxaBeeE"
      },
      "source": [
        "x = tf.random.uniform((1, 3))\n",
        "temp = create_look_ahead_mask(x.shape[1])\n",
        "temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xluDl5cXYy4y"
      },
      "source": [
        "##### スケール済み内積アテンション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do9vunk54Fpz"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/scaled_attention.png\" width=\"500\" alt=\"scaled_dot_product_attention\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X1njzW74HAA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Mj_DBe4JzA"
      },
      "source": [
        "Transformerで使われているアテンション関数は3つの入力；Q(query), K(key), V(value)を取ります。このアテンションの重みの計算に使われている式は下記の通りです。\n",
        "\n",
        "$$\\Large{Attention(Q, K, V) = softmax_k(\\frac{QK^T}{\\sqrt{d_k}}) V} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD2Hg8HA4L00"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsxEE_-Wa1gF"
      },
      "source": [
        "内積アテンションは、深度の平方根をファクターとしてスケールされています。これは、深度が大きくなると、内積が非常に大きくなり、ソフトマックス関数の勾配を計算すると非常に小さな値しか返さなくなってしまうためです。\n",
        "\n",
        "例えば、`Q`と`K`が平均0分散1だと思ってください。これらの行列積は、平均0分散は`dk`となります。したがって、（他の数字ではなく）*`dk`の平方根*をスケーリングに使うことで、`Q` と `K` の行列積においても平均 0 分散 1 となり、緩やかな勾配を持つソフトマックスが得られることが期待できるのです。\n",
        "\n",
        "マスクには、（負の無限大に近い）-1e9が掛けられています。これは、マスクがQとKのスケール済み行列積と合計され、ソフトマックスの直前に適用されるからです。目的は、これらのセルをゼロにしてしまうことで、大きなマイナスの入力は、ゼロに近い出力となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqKdWnLz4UMM"
      },
      "source": [
        "  \"\"\"アテンションの重みの計算\n",
        "  q, k, vは最初の次元が一致していること\n",
        "  k, vは最後から2番めの次元が一致していること\n",
        "  マスクは型（パディングかルックアヘッドか）によって異なるshapeを持つが、\n",
        "  加算の際にブロードキャスト可能であること\n",
        "  引数：\n",
        "    q: query shape == (..., seq_len_q, depth)\n",
        "    k: key shape == (..., seq_len_k, depth)\n",
        "    v: value shape == (..., seq_len_v, depth_v)\n",
        "    mask: (..., seq_len_q, seq_len_k) にブロードキャスト可能な\n",
        "          shapeを持つ浮動小数点テンソル。既定値はNone\n",
        "  \n",
        "  戻り値：\n",
        "    出力、アテンションの重み\n",
        "  \"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LazzUq3bJ5SH"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "  matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "  \n",
        "  # matmul_qkをスケール\n",
        "  dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "  # マスクをスケール済みテンソルに加算\n",
        "  if mask is not None:\n",
        "    scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "  # softmax は最後の軸(seq_len_k)について\n",
        "  # 合計が1となるように正規化\n",
        "  attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "  output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "  return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiqETnhCkoXh"
      },
      "source": [
        "ソフトマックス正規化がKに対して行われるため、その値がQに割り当てる重要度を決めることになります。\n",
        "\n",
        "出力は、アテンションの重みとV(value)ベクトルの積を表しています。これにより、注目したい単語がそのまま残され、それ以外の単語は破棄されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n90YjClyInFy"
      },
      "source": [
        "def print_out(q, k, v):\n",
        "  temp_out, temp_attn = scaled_dot_product_attention(\n",
        "      q, k, v, None)\n",
        "  print ('Attention weights are:')\n",
        "  print (temp_attn)\n",
        "  print ('Output is:')\n",
        "  print (temp_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAzUAf2DPlNt"
      },
      "source": [
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "temp_k = tf.constant([[10,0,0],\n",
        "                      [0,10,0],\n",
        "                      [0,0,10],\n",
        "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
        "\n",
        "temp_v = tf.constant([[   1,0],\n",
        "                      [  10,0],\n",
        "                      [ 100,5],\n",
        "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
        "\n",
        "# この`query`は2番目の`key`に割り付けられているので\n",
        "# 2番めの`value`が返される\n",
        "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg6k-fGhgXra"
      },
      "source": [
        "# このクエリは（3番目と 4番目の）繰り返しキーに割り付けられるので\n",
        "# 関連した全ての値が平均される\n",
        "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAq3YOzUgXhb"
      },
      "source": [
        "# このクエリは最初と2番めのキーに等しく割り付けられるので\n",
        "# それらの値が平均される\n",
        "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOz-4_XIhaTP"
      },
      "source": [
        "すべてのクエリをまとめます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dlU8Tm-hYrF"
      },
      "source": [
        "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
        "print_out(temp_q, temp_k, temp_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmzGPEy64qmA"
      },
      "source": [
        "##### マルチヘッド・アテンション"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP_Fjc4y4azV"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/multi_head_attention.png\" width=\"500\" alt=\"multi-head attention\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwskC4kK4b4l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz5BMC8Kaoqo"
      },
      "source": [
        "マルチヘッド・アテンションは4つのパートから成っています。\n",
        "* 線形レイヤーとマルチヘッドへの分割\n",
        "* スケール済み内積アテンション\n",
        "* マルチヘッドの結合\n",
        "* 最終線形レイヤー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNDFKNCB4fFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPmbr6F1C-v_"
      },
      "source": [
        "各マルチヘッド・アテンション・ブロックは3つの入力：Q(query), K(key), V(value)を取ります。\n",
        "これらは、線形（Dense）レイヤーを通され、マルチヘッドに分割されます。\n",
        "\n",
        "上記で定義した`scaled_dot_product_attention`は（効率のためにブロードキャストで）各ヘッドに適用されます。アテンション・ステップにおいては、適切なマスクを使用しなければなりません。その後、各ヘッドのアテンション出力は（`tf.transpose`と`tf.reshape`を使って）結合され、最後の`Dense`レイヤーに通されます。\n",
        "\n",
        "単一のアテンション・ヘッドのかわりに、Q、K、およびVは複数のヘッドに分割されます。なぜなら、それによって、モデルが異なる表現空間の異なる位置の情報について、連携してアテンションを計算できるからです。また、分割後の各ヘッドの次元を小さくすることで、全体の計算コストを、すべての次元を持つ単一のアテンション・ヘッドを用いた場合と同一にできます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSV3PPKsYecw"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "    \n",
        "    assert d_model % self.num_heads == 0\n",
        "    \n",
        "    self.depth = d_model // self.num_heads\n",
        "    \n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "    \n",
        "    self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "  def split_heads(self, x, batch_size):\n",
        "    \"\"\"最後の次元を(num_heads, depth)に分割。\n",
        "    結果をshapeが(batch_size, num_heads, seq_len, depth)となるようにリシェイプする。\n",
        "    \"\"\"\n",
        "    x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size = tf.shape(q)[0]\n",
        "    \n",
        "    q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "    k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "    v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "    \n",
        "    q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "    k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "    v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "    \n",
        "    # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "    # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "    scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "        q, k, v, mask)\n",
        "    \n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention, \n",
        "                                  (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "    output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "        \n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D8FJue5lDyZ"
      },
      "source": [
        "試しに、`MultiHeadAttention`レイヤーを作ってみましょう。シーケンス `y` の各位置において、`MultiHeadAttention` はシーケンスのすべての位置に対して8つのヘッドを用いてアテンションを計算し、各位置それぞれで同じ長さの新しいベクトルを返します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu94p-_-2_BX"
      },
      "source": [
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn = temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDqGayx67vv"
      },
      "source": [
        "##### ポイントワイズのフィードフォワード・ネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBqzJXGfHK3X"
      },
      "source": [
        "ポイントワイズのフィードフォワード・ネットワークは、2つの全結合層とそれをつなぐReLU活性化層からなります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET7xLt0yCT6Z"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "  return tf.keras.Sequential([\n",
        "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
        "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
        "  ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytb1lPyOHLB"
      },
      "source": [
        "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
        "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7hKcxn6-zd"
      },
      "source": [
        "##### エンコーダーとデコーダー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yScbC0MUH8dS"
      },
      "source": [
        "<img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\" width=\"600\" alt=\"transformer\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXGYnsTz4iFc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfYJG-Kvgwy2"
      },
      "source": [
        "Transformerモデルは、標準の[アテンション付きシーケンス・トゥー・シーケンスモデル](nmt_with_attention.ipynb)と同じ一般的なパターンを踏襲します。\n",
        "\n",
        "* 入力の文は、`N`層のエンコーダー・レイヤーを通り、シーケンス中の単語／トークンごとに出力を生成する。\n",
        "* デコーダーは、エンコーダーの出力と自分自身の入力（セルフアテンション）に注目し、次の単語を予測する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFv-FNYUmvpn"
      },
      "source": [
        "##### エンコーダー・レイヤー\n",
        "\n",
        "それぞれのエンコーダー・レイヤーは次のようなサブレイヤーから成っています。\n",
        "\n",
        "1.  マルチヘッド・アテンション（パディング・マスク付き）\n",
        "2.  ポイントワイズ・フィードフォワード・ネットワーク\n",
        "\n",
        "サブレイヤーにはそれぞれ残差接続があり、その後にレイヤー正規化が続きます。残差接続は、深いネットワークでの勾配消失問題を回避するのに役立ちます。\n",
        "\n",
        "それぞれのサブレイヤーの出力は`LayerNorm(x + Sublayer(x))`です。正規化は、（最後の）`d_model`軸に対して行われます。TransformerにはN層のエンコーダーがあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncyS-Ms3i2x_"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "\n",
        "    self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "    attn_output = self.dropout1(attn_output, training=training)\n",
        "    out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "    ffn_output = self.dropout2(ffn_output, training=training)\n",
        "    out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
        "    \n",
        "    return out2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzZRXdO0mI48"
      },
      "source": [
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LO_48Owmx_o"
      },
      "source": [
        "##### デコーダー・レイヤー\n",
        "\n",
        "各デコーダー・レイヤーは次のようなサブレイヤーからなります。\n",
        "\n",
        "1. マスク付きマルチヘッド・アテンション（ ルックアヘッド・マスクおよびパディング・マスク付き）\n",
        "2. （パディング・マスク付き）マルチヘッド・アテンション。V(value) と K(key) は*エンコーダーの出力*を入力として受け取る。Q(query)は*マスク付きマルチヘッド・アテンション・サブレイヤー*の出力を受け取る。\n",
        "3. ポイントワイズ・フィードフォワード・ネットワーク\n",
        "\n",
        "各サブレイヤーは残差接続を持ち、その後にレイヤー正規化が続きます。各サブレイヤーの出力は`LayerNorm(x + Sublayer(x))`です。正規化は、（最後の）`d_model`軸に沿って行われます。\n",
        "\n",
        "Transformerには、N層のデコーダー・レイヤーが存在します。\n",
        "\n",
        "Qがデコーダーの最初のアテンション・ブロックの出力を受け取り、Kがエンコーダーの出力を受け取るとき、アテンションの重みは、デコーダーの入力の、エンコーダーの出力に対する重要度を表します。言い換えると、デコーダーは、エンコーダーの出力と自分自身の出力のセルフ・アテンションを見て、次の単語を予想します。上記の、スケール済み内積アテンションのセクションのデモを参照してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SoX0-vd1hue"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "    super(DecoderLayer, self).__init__()\n",
        "\n",
        "    self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "    self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "    self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        " \n",
        "    self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "    \n",
        "    self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "    # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "    attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn1 = self.dropout1(attn1, training=training)\n",
        "    out1 = self.layernorm1(attn1 + x)\n",
        "    \n",
        "    attn2, attn_weights_block2 = self.mha2(\n",
        "        enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
        "    attn2 = self.dropout2(attn2, training=training)\n",
        "    out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "    ffn_output = self.dropout3(ffn_output, training=training)\n",
        "    out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "    \n",
        "    return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ne2Bqx8k71l0"
      },
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output, \n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE1H51Ajm0q1"
      },
      "source": [
        "##### エンコーダー\n",
        "\n",
        "`Encoder`は次のものからできています。\n",
        "\n",
        "1.  入力の埋め込み\n",
        "2.  位置エンコーディング\n",
        "3.  N 層のエンコーダー・レイヤー\n",
        "\n",
        "入力は埋め込み層を通り、位置エンコーディングと合算されます。この加算の出力がエンコーダー・レイヤーの入力です。エンコーダーの出力はデコーダーの入力になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpEox7gJ8FCI"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
        "                                            self.d_model)\n",
        "    \n",
        "    \n",
        "    self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "  \n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "  def call(self, x, training, mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    \n",
        "    # 埋め込みと位置エンコーディングを合算する\n",
        "    x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "    x = self.dropout(x, training=training)\n",
        "    \n",
        "    for i in range(self.num_layers):\n",
        "      x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "    return x  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QG9nueFQKXx"
      },
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print (sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-uO6ls8m2O5"
      },
      "source": [
        "##### デコーダー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtT7PKzrXkNr"
      },
      "source": [
        "`Decoder` は次のもとからできています。\n",
        " \n",
        "1.   出力埋め込み\n",
        "2.   位置エンコーディング\n",
        "3.   N 層のデコーダー・レイヤー\n",
        "\n",
        "ターゲットは埋め込みを通り、位置エンコーディングと加算されます。この加算の出力がデコーダーの入力になります。デコーダーの出力は、最後の線形レイヤーの入力となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5_d5-PLQXwY"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "               maximum_position_encoding, rate=0.1):\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "    \n",
        "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
        "                       for _ in range(num_layers)]\n",
        "    self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "  def call(self, x, enc_output, training, \n",
        "           look_ahead_mask, padding_mask):\n",
        "\n",
        "    seq_len = tf.shape(x)[1]\n",
        "    attention_weights = {}\n",
        "    \n",
        "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
        "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "    x += self.pos_encoding[:, :seq_len, :]\n",
        "    \n",
        "    x = self.dropout(x, training=training)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
        "                                             look_ahead_mask, padding_mask)\n",
        "      \n",
        "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "    # x.shape == (batch_size, target_seq_len, d_model)\n",
        "    return x, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jXoAMRZyvu"
      },
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8, \n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input, \n",
        "                              enc_output=sample_encoder_output, \n",
        "                              training=False,\n",
        "                              look_ahead_mask=None, \n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y54xnJnuYgJ7"
      },
      "source": [
        "##### Transformerの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uERO1y54cOKq"
      },
      "source": [
        " Transformerは、エンコーダー、デコーダーと、最後の線形レイヤーからなります。デコーダーの出力は、線形レイヤーの入力であり、その出力が返されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PED3bIpOYkBu"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "  def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
        "               target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "    super(Transformer, self).__init__()\n",
        "\n",
        "    self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
        "                           input_vocab_size, pe_input, rate)\n",
        "\n",
        "    self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
        "                           target_vocab_size, pe_target, rate)\n",
        "\n",
        "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "  def call(self, inp, tar, training, enc_padding_mask, \n",
        "           look_ahead_mask, dec_padding_mask):\n",
        "\n",
        "    enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
        "    \n",
        "    # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "    dec_output, attention_weights = self.decoder(\n",
        "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "    \n",
        "    final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
        "    \n",
        "    return final_output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ4fbQcIkHW1"
      },
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048, \n",
        "    input_vocab_size=8500, target_vocab_size=8000, \n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer(temp_input, temp_target, training=False, \n",
        "                               enc_padding_mask=None, \n",
        "                               look_ahead_mask=None,\n",
        "                               dec_padding_mask=None)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsINyf1VEQLC"
      },
      "source": [
        "##### ハイパーパラメーターの設定"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVjWCxFNcgbt"
      },
      "source": [
        "このサンプルを小さく、比較的高速にするため、 *num_layers, d_model, and dff*の値は小さくされています。\n",
        "\n",
        "Transformerのベースモデルで使われている値は*num_layers=6*, *d_model = 512*, *dff = 2048*です。 Transformerの他のバージョンについては、[論文](https://arxiv.org/abs/1706.03762)を参照してください。\n",
        "\n",
        "Note: 下記の値を変更することで、さまざまなタスクでSoTA（訳注：State of The Art、その時点での最高性能）を達成したモデルが得られます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnJn5SLA2ahP"
      },
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "\n",
        "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
        "target_vocab_size = tokenizer_en.vocab_size + 2\n",
        "dropout_rate = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYEGhEOtzn5W"
      },
      "source": [
        "##### オプティマイザー"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOmWW--yP3zx"
      },
      "source": [
        "[論文](https://arxiv.org/abs/1706.03762)の中の式に従って、カスタムの学習率スケジューラーを持った、Adamオプティマイザーを使用します。\n",
        "\n",
        "$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYQdOO1axwEI"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "    \n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "    \n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7r4scdulztRx"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f33ZCgvHpPdG"
      },
      "source": [
        "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgkDE7hzo8r5"
      },
      "source": [
        "##### 損失とメトリクス"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxGJtoDuYIHL"
      },
      "source": [
        "ターゲットシーケンスはパディングされているため、損失を計算する際にパディング・マスクを適用することが重要です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlhsJMm0TW_B"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67oqVHiT0Eiu"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phlyxMnm-Tpx"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "    name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeHumfr7zmMa"
      },
      "source": [
        "##### 訓練とチェックポイント生成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiysUa--4tOU"
      },
      "source": [
        "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
        "                          input_vocab_size, target_vocab_size, \n",
        "                          pe_input=input_vocab_size, \n",
        "                          pe_target=target_vocab_size,\n",
        "                          rate=dropout_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOJUSB1T8GjM"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "  # Encoderパディング・マスク\n",
        "  enc_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # デコーダーの 2つ目のアテンション・ブロックで使用\n",
        "  # このパディング・マスクはエンコーダーの出力をマスクするのに使用\n",
        "  dec_padding_mask = create_padding_mask(inp)\n",
        "  \n",
        "  # デコーダーの 1つ目のアテンション・ブロックで使用\n",
        "  # デコーダーが受け取った入力のパディングと将来のトークンをマスクするのに使用\n",
        "  look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "  dec_target_padding_mask = create_padding_mask(tar)\n",
        "  combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "  return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzuf06YZp66w"
      },
      "source": [
        "チェックポイントのパスとチェックポイント・マネージャーを作成します。これは、`n`エポックごとにチェックポイントを保存するのに使用されます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNhuYfllndLZ"
      },
      "source": [
        "checkpoint_path = \"./checkpoints/train\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "# チェックポイントが存在したなら、最後のチェックポイントを復元\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "  ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "  print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Di_Yaa1gf9r"
      },
      "source": [
        "ターゲットは、tar_inpとtar_realに分けられます。tar_inpはデコーダーの入力として渡されます。`tar_real`は同じ入力を1つシフトしたものです。`tar_input`の位置それぞれで、`tar_real`は予測されるべき次のトークンを含んでいます。\n",
        "\n",
        "たとえば、`sentence` = \"SOS A lion in the jungle is sleeping EOS\" だとすると、次のようになります。\n",
        "\n",
        "`tar_inp` =  \"SOS A lion in the jungle is sleeping\"\n",
        "\n",
        "`tar_real` = \"A lion in the jungle is sleeping EOS\"\n",
        "\n",
        "Transformerは、自己回帰モデルです。1回に1箇所の予測を行い、その出力を次に何をすべきかの判断に使用します。\n",
        "\n",
        "訓練時にこのサンプルは[テキスト生成チュートリアル](./text_generation.ipynb)のように、ティーチャーフォーシングを使用します。ティーチャーフォーシングとは、その時点においてモデルが何を予測したかに関わらず、真の出力を次のステップに渡すというものです。\n",
        "\n",
        "Transformerが単語を予測するたびに、*セルフアテンション*のおかげで次の単語を予測するために入力シーケンスの過去の単語を参照することができます。\n",
        "\n",
        "モデルが期待される出力を盗み見ることがないように、モデルはルックアヘッド・マスクを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKpoA6q1sJFj"
      },
      "source": [
        "EPOCHS = 5 ### 20 -> 5\n",
        "\n",
        "### 学習の所要時間：1エポック1分かからないくらい"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJwmp9OE29oj"
      },
      "source": [
        "# @tf.functionは高速に実行するためにtrain_stepをTFグラフにトレースコンパイルします。\n",
        "# この関数は、引数となるテンソルのshapeに特化したものです。\n",
        "# シーケンスの長さや（最後のバッチが小さくなるなど）バッチサイズが可変となることによって\n",
        "# 再トレーシングが起きないようにするため、input_signatureを使って、より一般的なshapeを\n",
        "# 指定します。\n",
        "\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "  tar_inp = tar[:, :-1]\n",
        "  tar_real = tar[:, 1:]\n",
        "  \n",
        "  enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "  \n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions, _ = transformer(inp, tar_inp, \n",
        "                                 True, \n",
        "                                 enc_padding_mask, \n",
        "                                 combined_mask, \n",
        "                                 dec_padding_mask)\n",
        "    loss = loss_function(tar_real, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "  optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM2PDWGDJ_8V"
      },
      "source": [
        "ポルトガル語を入力言語とし、英語をターゲット言語とします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvmaKNiznHZ"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  \n",
        "  # inp -> portuguese, tar -> english\n",
        "  for (batch, (inp, tar)) in enumerate(train_dataset):\n",
        "    train_step(inp, tar)\n",
        "    \n",
        "    if batch % 50 == 0:\n",
        "      print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "          epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "      \n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    ckpt_save_path = ckpt_manager.save()\n",
        "    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "                                                         ckpt_save_path))\n",
        "    \n",
        "  print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
        "                                                train_loss.result(), \n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "  print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfcsSWswSdGV"
      },
      "source": [
        "##### 評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6APsFrgImLW"
      },
      "source": [
        "評価は次のようなステップで行われます。\n",
        "\n",
        "* ポルトガル語のトークナイザー(`tokenizer_pt`)を使用して入力文をエンコードします。さらに、モデルの訓練に使用されたものと同様に、開始および終了トークンを追加します。これが、入力のエンコードです。\n",
        "* デコーダーの入力は、`start token == tokenizer_en.vocab_size`です。\n",
        "* パディング・マスクとルックアヘッド・マスクを計算します。\n",
        "* `decoder`は、`encoder output`と自分自身の出力（セルフアテンション）を見て、予測値を出力します。\n",
        "* 最後の単語を選択し、そのargmaxを計算します。\n",
        "* デコーダーの入力に予測された単語を結合し、デコーダーに渡します。\n",
        "* このアプローチでは、デコーダーは自分自身が予測した過去の単語にもとづいて次の単語を予測します。\n",
        "\n",
        "Note: ここで使われているモデルは、より早く実行できるようにした能力の低いものであるため、予測はあまり正確ではありません。論文の結果を再現するには、データセット全体を使用し、上記のハイパーパラメーターを変更して、ベースのTransformerモデルまたはTransformer XLを使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5buvMlnvyrFm"
      },
      "source": [
        "def evaluate(inp_sentence):\n",
        "  start_token = [tokenizer_pt.vocab_size]\n",
        "  end_token = [tokenizer_pt.vocab_size + 1]\n",
        "  \n",
        "  # inp文はポルトガル語、開始および終了トークンを追加\n",
        "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
        "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
        "  \n",
        "  # ターゲットは英語であるため、Transformerに与える最初の単語は英語の\n",
        "  # 開始トークンとなる\n",
        "  decoder_input = [tokenizer_en.vocab_size]\n",
        "  output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "  for i in range(MAX_LENGTH):\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "        encoder_input, output)\n",
        "  \n",
        "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
        "    predictions, attention_weights = transformer(encoder_input, \n",
        "                                                 output,\n",
        "                                                 False,\n",
        "                                                 enc_padding_mask,\n",
        "                                                 combined_mask,\n",
        "                                                 dec_padding_mask)\n",
        "    \n",
        "    # seq_len次元から最後の単語を選択\n",
        "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
        "\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "    \n",
        "    # predicted_idが終了トークンと等しいなら結果を返す\n",
        "    if predicted_id == tokenizer_en.vocab_size+1:\n",
        "      return tf.squeeze(output, axis=0), attention_weights\n",
        "    \n",
        "    # 出力にpredicted_idを結合し、デコーダーへの入力とする\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN-BV43FMBej"
      },
      "source": [
        "def plot_attention_weights(attention, sentence, result, layer):\n",
        "  fig = plt.figure(figsize=(16, 8))\n",
        "  \n",
        "  sentence = tokenizer_pt.encode(sentence)\n",
        "  \n",
        "  attention = tf.squeeze(attention[layer], axis=0)\n",
        "  \n",
        "  for head in range(attention.shape[0]):\n",
        "    ax = fig.add_subplot(2, 4, head+1)\n",
        "    \n",
        "    # アテンションの重みをプロット\n",
        "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 10}\n",
        "    \n",
        "    ax.set_xticks(range(len(sentence)+2))\n",
        "    ax.set_yticks(range(len(result)))\n",
        "    \n",
        "    ax.set_ylim(len(result)-1.5, -0.5)\n",
        "        \n",
        "    ax.set_xticklabels(\n",
        "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
        "        fontdict=fontdict, rotation=90)\n",
        "    \n",
        "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
        "                        if i < tokenizer_en.vocab_size], \n",
        "                       fontdict=fontdict)\n",
        "    \n",
        "    ax.set_xlabel('Head {}'.format(head+1))\n",
        "  \n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lU2_yG_vBGza"
      },
      "source": [
        "def translate(sentence, plot=''):\n",
        "  result, attention_weights = evaluate(sentence)\n",
        "  \n",
        "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
        "                                            if i < tokenizer_en.vocab_size])  \n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Predicted translation: {}'.format(predicted_sentence))\n",
        "  \n",
        "  if plot:\n",
        "    plot_attention_weights(attention_weights, sentence, result, plot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsxrAlvFG8SZ"
      },
      "source": [
        "translate(\"este é um problema que temos que resolver.\")\n",
        "print (\"Real translation: this is a problem we have to solve .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EH5y_aqI4t1"
      },
      "source": [
        "translate(\"os meus vizinhos ouviram sobre esta ideia.\")\n",
        "print (\"Real translation: and my neighboring homes heard about this idea .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-hVCTSUMlkb"
      },
      "source": [
        "translate(\"vou então muito rapidamente partilhar convosco algumas histórias de algumas coisas mágicas que aconteceram.\")\n",
        "print (\"Real translation: so i 'll just share with you some stories very quickly of some magical things that have happened .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1MxkSZvz0jX"
      },
      "source": [
        "パラメータを`plot`するために、異なるレイヤーやデコーダーのアテンション・ブロックを渡すことができます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-kFyiOLH0xg"
      },
      "source": [
        "translate(\"este é o primeiro livro que eu fiz.\", plot='decoder_layer4_block2')\n",
        "print (\"Real translation: this is the first book i've ever done.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqQ1fIsLwkGE"
      },
      "source": [
        "##### まとめ\n",
        "\n",
        "このチュートリアルでは、位置エンコーディング、マルチヘッド・アテンション、マスキングの重要性と、 Transformerの作成方法を学習しました。\n",
        "\n",
        "Transformerを訓練するために、異なるデータセットを使ってみてください。また、上記のハイパーパラメーターを変更してベースTransformerやTransformer XLを構築することもできます。ここで定義したレイヤーを使って[BERT](https://arxiv.org/abs/1810.04805)を構築して、SoTAのモデルを作ることもできます。さらには、より良い予測を得るために、ビームサーチを組み込むこともできます。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3e9mIl0vZ5k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}